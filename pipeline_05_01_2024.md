
# Genetic analysis of Multiple Sclerosis in diverse ancestries
### A genetic _A_ssociation Study of individuals of _D_iverse _A_ncestral backgrounds with _M_ultiple _S_clerosis (ADAMS)<a href =https://app.mantal.co.uk/adams><p><center> <img src="https://app.mantal.co.uk/files/db2440daa093e6b2d688b8a02b82cff2.png" width=20% height=40%></a></p></center>


This repo contains code used to analyze data from the ADAMS project - a genotype-phenotype cohort of people with Multiple Sclerosis focussed on those from diverse ancestral backgrounds. The baseline cohort description is [here](https://bmjopen.bmj.com/content/13/5/e071656.full).

# Code
Prior to imputation genotypes were called using Illumina Genome Studio v2.0. Raw PLINK binary files (.map and .ped) were exported from Genome Studio with calls coerced to the forward strand.

## Imputation
### Initial genotype quality control
First the .ped and .map files are converted to PLINK1 binary format with some light QC.
- Conversion to PLINK1 binary
- Basic QC pre-imputation: autosomes, missingess for genotypes and people <10%, MAC > 10, HWE deviation

````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23

~/plink --file /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/raw/ADAMS_16_01_24 \
--make-bed \
--chr 1-22 \
--geno 0.1 \
--hwe 1e-10 \
--mac 20 \
--mind 0.01 \
--out ./outputs/ADAMS_geno
````

#### Update FIDs to IIDs
````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23
awk '{print $1,$2,$2,$2}'  ./outputs/ADAMS_geno.fam > ./outputs/new_ids
~/plink --bfile ./outputs/ADAMS_geno \
--update-ids ./outputs/new_ids \
--make-bed \
--out ./outputs/ADAMS_geno_fid_iid
````

#### Remove people missing in phenotype data
````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23
~/plink --bfile ./outputs/ADAMS_geno_fid_iid \
--keep ./pheno/adams_pheno.tsv \
--make-bed \
--out ./outputs/ADAMS_geno_fid_iid_inpheno
````


### Kinship / duplicates
````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/
~/king -b ADAMS_geno_fid_iid_inpheno.bed --duplicate
````

#### Download king.con & run
#### explore_duplicates.R on QM server
#### upload ids_to_exclude.tsv
#### Remove duplicates
````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23
~/plink --bfile ./outputs/ADAMS_geno_fid_iid_inpheno \
--remove ./outputs/ids_to_exclude.tsv \
--make-bed \
--out ./outputs/ADAMS_geno_fid_iid_inpheno_nodups

cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/
~/king -b ADAMS_geno_fid_iid_inpheno_nodups.bed --duplicate
~/king -b ADAMS_geno_fid_iid_inpheno_nodups.bed --related --degree 3
````

#### Missingness
````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23
~/plink --bfile ./outputs/ADAMS_geno_fid_iid_inpheno_nodups \
--missing \
--out miss_check

````
#### Heterozygosity
````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23
~/plink --bfile ./outputs/ADAMS_geno_fid_iid_inpheno_nodups \
--het small-sample \
--out het_check
````

````R
library(tidyverse)
setwd("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23")
het = read_table("het_check.het")


p=ggplot(het,aes(F))+
	geom_histogram()+
	theme_minimal()+
	labs(x="Heterozygosity statistic (F)",y="N")+
	geom_vline(xintercept = mean(het$F)-5*sd(het$F),linetype="dashed",color="blue")+
	geom_vline(xintercept = mean(het$F)+5*sd(het$F),linetype="dashed",color="blue")
png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/het_stats.png",res=900,units="in",width=4,height=4)
p
dev.off()

````
#### Sex check
````R
library(tidyverse)
setwd("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23")

fam_file = read_table("./outputs/ADAMS_geno_fid_iid_inpheno_nodups.fam",col_names=F)
covars = read_tsv("./pheno/adams_covars.tsv")
fam_file = fam_file %>%
	dplyr::rename("IID" = X1) %>%
	left_join(covars,by="IID")

fam_file %>%
	group_by(Sex) %>%
	dplyr::count(X5) %>%
	mutate(prop = n/sum(n))

# plot
ggplot(fam_file,aes(Sex,fill=factor(X5)))+
	geom_bar(position="fill",color="black")

````

### Export VCFs

````unix
# flip strand
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23
for i in {1..22};
do
	~/plink --bfile ./outputs/ADAMS_geno_fid_iid_inpheno_nodups \
	--chr $i \
	--recode vcf \
	--output-chr chrMT \
	--out ./imputation_raw_files/chr$i &
done
````

### Sort with bcf tools
````unix
module load bcftools
for i in {1..22};
do
  bcftools sort ./imputation_raw_files/chr$i\.vcf \
  -Oz -o ./imputation_raw_files/sorted_chr$i\.vcf.gz &
done
````

### First pass imputation
- Attempt imputation at TOPMED server (TOPMED-R3)
- This will fail due to strand flips
- Download excluded snps and use strand flips to flip

````unix
# wget https://imputation.biodatacatalyst.nhlbi.nih.gov/results/job-20230901-122606-755/statisticDir/snps-excluded.txt

awk 'FS="\t"{if($2=="Strand flip") print $1}' ./imputation_raw_files/snps-excluded.txt > ./imputation_raw_files/snps_to_flip
awk 'FS="\t"{if($2!="Strand flip") print $1}' ./imputation_raw_files/snps-excluded.txt | uniq > ./imputation_raw_files/snps_to_exclude

# set var IDs to chr:pos:ref:alt
for i in {1..22};
do
	~/plink2 --vcf ./imputation_raw_files/chr$i\.vcf \
	--set-all-var-ids chr@:#:\$r\:\$a \
	--make-bed \
	--out ./imputation_raw_files/updated_ids_chr$i &
done

# recode VCFs
for i in {1..22};
do
	~/plink --bfile ./imputation_raw_files/updated_ids_chr$i \
	--exclude ./imputation_raw_files/snps_to_exclude \
	--out ./imputation_raw_files/flipped_chr$i \
	--output-chr chrMT \
	--recode vcf &
done

# flip strands
for i in {1..22};
do
	~/plink --vcf ./imputation_raw_files/flipped_chr$i\.vcf --double-id \
	--flip ./imputation_raw_files/snps_to_flip \
	--out ./imputation_raw_files/dbl_flipped_chr$i \
	--output-chr chrMT \
	--recode vcf &
done

	# sort with bcf tools
module load bcftools
for i in {1..22};
do
	bcftools sort ./imputation_raw_files/dbl_flipped_chr$i\.vcf \
	 -Oz -o ./imputation_raw_files/sorted_chr$i\.vcf.gz &
done
````

###########################
### Download imputed data
###########################

### 2nd pass imputation
- Performed imputation again
- Download imputed data
- Rsq filter 0.001
- TOPMED-r3

````unix
cd /data/scratch/hmy117/adams_imputed

wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/d7a25dc866a65bd63cb4a4067159d85198dc6023b01480600e7d23aede14fb16/chr_1.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/eb5b07fca297cd98b43e9b7dc83718f34e636e3ca1fa3b0abb98a74406bdbf44/chr_10.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/a1dbea2988d4dee952d906bb15f94ab0d66cbc0a05029cd367bfac3172dd6741/chr_11.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/677c338bbe78f55279fdcb089797d7f27cbe16ad75cf0f6d01559ee7f200a1fe/chr_12.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/6f4c37f14c4fbb9b25372448d2d57055b05a9ad10e8b04c848c28ca253eb1e38/chr_13.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/8c99bdabec3599885d19c4035dcaafafcade23a9f0d321c79e45283ad9f97ccb/chr_14.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/539b1d02c3ea59873a448142451eef07cfe0e57d45e463175667ca459fed37c4/chr_15.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/4f55f533b68bfd22c89ba5f2a1addfe6ea7caaff7b60189780bfdfc9d2f57268/chr_16.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/128d7c3f5489f1efd906d94f05cf1ef6220b912e62ad1f0e10428e73a6905287/chr_17.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/95a4d57f8283707acb0b6d8b85a4e38a2a48513e46a0f0795475b71079f86d88/chr_18.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/06794fb7a71606baa8ef54ad1e8af1a1a80a1adab02668a04448ebe6c6719523/chr_19.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/dfb1c399b286aeb2d40b34b78b0e550cf27796f89ac59bcf5d9c888fec356ee3/chr_2.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/592e31c53ca50a9d41cd2bb24047f9793dd79ca477fd7e5dbeed3d9590f9e01c/chr_20.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/df298e8b3eab1e8f71682280635e61c756ada0f4ce05708d46e695f8ca5bebf0/chr_21.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/0e20bb858e52b73e0ac920fe4ee7999bce67d4986d1ef6d7735bf2caab3fd562/chr_22.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/bb8981e8025ead8cd7da6779fb363aab0e762b2c9fff2a2974c8cb81f3064e08/chr_3.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/af927d519118be1fdfbb2df2bada73ac7b58bfa38b696b08b30bd4f25900afaa/chr_4.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/d3c79e79f5db2febdeb5e69310791bbef8625e16bc2b14edfee305ed09cc8567/chr_5.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/cabd159975ce321d6da95280eb0d4838b331f72bb0040cc766c28bf9a039d523/chr_6.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/282f0d22969ffe45b340cf316f75975e05b3bdce7f93bee431e8ab4087f0a399/chr_7.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/317e84d729b7f3f44f5c5f33280c00ff4798d7cc5004fca268cd9c758c4ce462/chr_8.zip &
wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/eb0994cd8288bef8513d2781ae8359381ebeb8086fe93b29599512a2e483227c/chr_9.zip &

# unzip
for i in {1..22};
do
  unzip -o -P rZvZSBy4p0NiXw chr_$i\.zip.1 &
done

````

### HLA imputation
- HLA imputation run via MIS https://imputationserver.sph.umich.edu/index.html#!run/imputationserver-hla
- Note that this output is _hg19_
````unix
cd /data/scratch/hmy117/adams_imputed
wget https://imputationserver.sph.umich.edu/share/results/503cd6ac93b7dd8e208374b21b169d58fd9a1d6065f811492afed12a0e8ac2c1/chr_6.zip
unzip -P "pV)PSgZfUt4pu2" chr_6.zip

````

## Ancestry inference

### Liftover (for bigSNPR ancestry)
````unix

cd /data/scratch/hmy117/hgdp_1kg_genomes/
# lift over to hg19
awk '{print "chr"$1,$4-1,$4,$2}' /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ADAMS_geno_fid_iid_inpheno_nodups.bim > hg38_bedfile

# run liftover
/data/Wolfson-UKBB-Dobson/liftover/liftOver \
hg38_bedfile \
/data/Wolfson-UKBB-Dobson/liftover/hg38ToHg19.over.chain.gz \
hg19_bedfile \
unmapped

awk '{print $4,$1":"$3":"$4}' hg19_bedfile > hg19_snps
awk '{print $1":"$3":"$4,$3}' hg19_bedfile > hg19_snp_positions

# Update SNP positions and IDs
~/plink --bfile /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ADAMS_geno_fid_iid_inpheno_nodups \
--update-name hg19_snps \
--make-bed \
--out adams_temp_hg19_for_bigsnpr

~/plink --bfile adams_temp_hg19_for_bigsnpr \
--update-map hg19_snp_positions \
--make-bed \
--out adams_hg19_for_bigsnpr_cpra
````

### Download reference data
````unix
# run with qsub ./scripts/download_hgdp_1kg.sh
#!/bin/bash
#$ -pe smp 4
#$ -l h_vmem=4G
#$ -l h_rt=240:0:0
#$ -j y
#$ -N download_hgdp_genomes
#$ -o /data/scratch/hmy117
#$ -t 1:22

~/google-cloud-sdk/bin/gsutil cp \
gs://gcp-public-data--gnomad/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.hgdp_tgp.chr${SGE_TASK_ID}\.vcf.bgz \
/data/scratch/hmy117/hgdp_1kg_genomes
````

### Filter to ADAMS variants
````R
library(tidyverse)
df = read_table("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ADAMS_geno_fid_iid_inpheno_nodups.bim",col_names=F) %>%
  dplyr::select(2)
message(nrow(df)," SNPs")
df$X2 = str_remove_all(df$X2,"GSA-")
df = df %>%
  filter(grepl("^rs",X2))
message(nrow(df)," SNPs with rsids")

write_tsv(df,"/data/scratch/hmy117/hgdp_1kg_genomes/adams_snps_for_filtering.tsv")
````
### Filter HGDP genomes to ADAMS genotyped variants
````unix
#qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/filter_hgdp_to_adams_vars.sh
#!/bin/bash
#$ -pe smp 4
#$ -l h_vmem=4G
#$ -l h_rt=240:0:0
#$ -j y
#$ -N download_hgdp_genomes
#$ -o /data/scratch/hmy117
#$ -t 1:22

module load plink/1.9-170906
cd /data/scratch/hmy117/hgdp_1kg_genomes/

plink --vcf gnomad.genomes.v3.1.2.hgdp_tgp.chr${SGE_TASK_ID}\.vcf.bgz \
--double-id \
--extract adams_snps_for_filtering.tsv \
--make-bed \
--out filtered_1kg_hgdp_1kg_chr${SGE_TASK_ID}
````

### Download ancestry calls
````unix
~/google-cloud-sdk/bin/gsutil cp \
gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg/data_intersection/hgdp_1kg_sample_info.unrelateds.pca_outliers_removed.with_project.tsv \
/data/scratch/hmy117/hgdp_1kg_genomes/
````

### Merge hgdp-1kg
````unix
cd /data/scratch/hmy117/hgdp_1kg_genomes/
for i in {2..22};
  do
    echo filtered_1kg_hgdp_1kg_chr$i >> merge_filelist
  done

cd /data/scratch/hmy117/hgdp_1kg_genomes/

# try merge
~/plink --bfile filtered_1kg_hgdp_1kg_chr1 \
--merge-list merge_filelist \
--make-bed \
--biallelic-only \
--out combined_hgdp_1kg

# remove duplicates & do QC
for i in {1..22};
  do
    ~/plink --bfile filtered_1kg_hgdp_1kg_chr$i \
    --exclude combined_hgdp_1kg-merge.missnp \
    --make-bed \
    --out hgdp_1kg_nodups_chr$i \
    --maf 0.05 \
    --geno 0.01 \
    --hwe 1e-10
  done

# try merge again
rm merge_filelist
for i in {2..22};
  do
    echo hgdp_1kg_nodups_chr$i >> merge_filelist
  done
~/plink --bfile hgdp_1kg_nodups_chr1 \
--merge-list merge_filelist \
--make-bed \
--biallelic-only \
--out combined_hgdp_1kg_filtered

````

### Do same QC for adams
````unix

cd /data/scratch/hmy117/hgdp_1kg_genomes/
~/plink --bfile /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ADAMS_geno_fid_iid_inpheno_nodups \
--extract combined_hgdp_1kg.bim \
--out ADAMS_qc_genos_for_pcs \
--make-bed
````

### Missingness filter
````unix
~/plink --bfile combined_hgdp_1kg_filtered \
--mind 0.1 \
--out combined_hgdp_1kg_nonmissing \
--make-bed
````

### Get intersection of nonpalindromic, compatible snps
````R
library(tidyverse)
adams_snps = read_table("ADAMS_qc_genos_for_pcs.bim",col_names=F)
kg_snps = read_table("combined_hgdp_1kg_nonmissing.bim",col_names=F)

# filter
adams_snps = adams_snps %>% filter(X2 %in% kg_snps$X2)
kg_snps = kg_snps %>% filter(X2 %in% adams_snps$X2)

# merge
combo = adams_snps %>% left_join(kg_snps,by="X2")

# filter to compatible alleles & filter out palindromes
combo = combo %>%
  filter(
      (X5.x == X5.y & X6.x == X6.y ) |
      (X5.x == X6.y & X6.x == X5.y )
      ) %>%
    filter(
      ! ( X5.x == "G" & X5.y == "C") &
      ! ( X5.x == "C" & X5.y == "G") &
      ! ( X5.x == "A" & X5.y == "T") &
      ! ( X5.x == "T" & X5.y == "A")
      )

combo = combo %>% dplyr::select(X2)
write_tsv(combo,"snps_to_keep.tsv",col_names=F)
````

### Project PCs
````unix

# rename as cpra
~/plink2 --bfile combined_hgdp_1kg_nonmissing \
--extract snps_to_keep.tsv \
--make-bed \
--out combined_hgdp_1kg_hg38

~/plink2 --bfile combined_hgdp_1kg_hg38 \
--set-all-var-ids @:#:\$r\:\$a \
--make-bed \
--out combined_hgdp_1kg_hg38_cpra

# filter to compatible snps
# remove related indivs
~/king -b combined_hgdp_1kg_hg38_cpra.bed --degree 3
awk 'NR>1{print $1,$2}' king.kin0 > indivs_to_remove
~/plink --bfile combined_hgdp_1kg_hg38_cpra \
--remove indivs_to_remove \
--out combined_hgdp_1kg_unrelated \
--make-bed

# prune 1kg
~/plink --bfile combined_hgdp_1kg_unrelated \
--indep-pairwise 1000 100 0.1 \
--out pruned_snps_hgdp_1kg

# filter
~/plink --bfile combined_hgdp_1kg_unrelated \
--out pruned_hgdp_1kg \
--extract pruned_snps_hgdp_1kg.prune.in \
--make-bed

# calculate PCs
~/plink2 --bfile pruned_hgdp_1kg \
--pca allele-wts 50 \
--freq \
--out hgdp_kg_pcs

# rename ADAMS as cpra
~/plink2 --bfile ADAMS_qc_genos_for_pcs \
--set-all-var-ids @:#:\$r\:\$a \
--make-bed \
--out adams_geno_for_pcs_hg38_cpra

# project ADAMS samples
~/plink2 --bfile adams_geno_for_pcs_hg38_cpra \
--read-freq hgdp_kg_pcs.afreq \
--score hgdp_kg_pcs.eigenvec.allele 2 5 header-read no-mean-imputation variance-normalize list-variants \
--score-col-nums 6-55 \
--out adams_pcs

# project original dataset
~/plink2 --bfile pruned_hgdp_1kg \
--read-freq hgdp_kg_pcs.afreq \
--extract adams_pcs.sscore.vars \
--score hgdp_kg_pcs.eigenvec.allele 2 5 header-read no-mean-imputation variance-normalize \
--score-col-nums 6-55 \
--out hgdp_kg_pcs_rescored

````

### Download metadata
wget https://storage.googleapis.com/gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg/metadata_and_qc/gnomad_meta_v1.tsv


### Ancestry inference
````R
library(tidyverse)
setwd("/data/scratch/hmy117/hgdp_1kg_genomes")

# read in data
adams = read_table("adams_pcs.sscore")
kg_hgdp = read_table("hgdp_kg_pcs_rescored.sscore")
meta = read_tsv("gnomad_meta_v1.tsv") %>%
  dplyr::select(2,hgdp_tgp_meta.Population,hgdp_tgp_meta.Genetic.region)
colnames(meta) = c("IID","pop","superpop")
kg_hgdp = kg_hgdp %>%
left_join(meta,by="IID")

# build RF on HGDP data
# filter out those with missing labels
kg_hgdp = kg_hgdp %>%
  filter(!is.na(superpop)) %>%
  dplyr::select(superpop,contains("PC"))
library(caret)

rf_fit = train(superpop ~ .,
                      data=kg_hgdp,
                      method='rf',
                      metric='Accuracy')


# save rf
saveRDS(rf_fit,"rf_fit.rds")

# can reload here
# rf_fit = readRDS("rf_fit.rds")

# predict
adams$predicted_ancestry = predict(rf_fit,adams)

# count
counts = adams %>% dplyr::count(predicted_ancestry) %>% mutate(pct = n/sum(n))
counts = counts %>% arrange(desc(n))
counts$predicted_ancestry= factor(counts$predicted_ancestry,levels = counts$predicted_ancestry,ordered=T)
p=ggplot(counts,aes(n,predicted_ancestry,fill=predicted_ancestry,
	label=paste0(round(pct*100,2),"%")))+
	geom_col(color="black")+
	scale_fill_brewer(palette="Set1")+
	theme_minimal()+
	geom_text(hjust=0,position=position_nudge(x=10))+
	scale_x_continuous(limits = c(0,400))+
	labs(x="N",y="Inferred genetic ancestry")+
	theme(legend.position="none")
png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_counts.png",res=900,units="in",width=4,height=3)
p
dev.off()

adams %>%
	dplyr::count(predicted_ancestry) %>%
	mutate(total = sum(n), prop = n/total)

p=ggplot(adams,aes(PC1_AVG,PC2_AVG,col=predicted_ancestry))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC1",y="PC2",col="Inferred genetic ancestry")

p2=ggplot(adams,aes(PC1_AVG,PC2_AVG,col=predicted_ancestry))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC1",y="PC2",col="Genetic ancestry")+
  ggtitle("ADAMS")+
	scale_x_continuous(limits = c(-0.2,0.2))+
	scale_y_continuous(limits = c(-0.15,0.15))

p3 = ggplot(kg_hgdp %>% na.omit(),aes(PC1_AVG,PC2_AVG,col=superpop))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC1",y="PC2",col="Genetic ancestry")+
  ggtitle("1kg + HGDP reference")+
	scale_x_continuous(limits = c(-0.2,0.2))+
	scale_y_continuous(limits = c(-0.15,0.15))

p4=ggplot(adams,aes(PC3_AVG,PC4_AVG,col=predicted_ancestry))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC3",y="PC4",col="Genetic ancestry")+
  ggtitle("ADAMS")+
	scale_y_continuous(limits = c(-0.25,0.05))+
	scale_x_continuous(limits = c(-0.15,0.15))
p5 = ggplot(kg_hgdp %>% na.omit(),aes(PC3_AVG,PC4_AVG,col=superpop))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC3",y="PC4",col="Genetic ancestry")+
  ggtitle("1kg + HGDP reference")+
	scale_y_continuous(limits = c(-0.25,0.05))+
	scale_x_continuous(limits = c(-0.15,0.15))

png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/pc_plot_with_ref_pc1_4.png",res=900,units="in",width=10,height=8)
cowplot::plot_grid(p2,p4,p3,p5,align="v",ncol=2)
dev.off()

# write all ancestry calls
anc_calls = adams %>%
  dplyr::select(1,2,predicted_ancestry)
write_tsv(anc_calls,"/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls.tsv")

# combine with self-reported ethnicity
covars = read_tsv("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/pheno/adams_covars.tsv")
adams = adams %>%
	left_join(covars,by="IID")

# plot

ethnicity_ancestry_counts = adams %>% group_by(ethnicity_clean) %>%
dplyr::count(predicted_ancestry) %>%
mutate(prop = n/sum(n),total = sum(n))
ethnicity_ancestry_counts
write_csv(ethnicity_ancestry_counts,"/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/anc_vs_ethnicity.csv")
p = ggplot(ethnicity_ancestry_counts %>% filter(!is.na(ethnicity_clean)),
aes(prop,ethnicity_clean,fill=predicted_ancestry,label = paste0("N = ",total)))+
geom_col(color="black")+
geom_text(data = ethnicity_ancestry_counts %>% distinct(ethnicity_clean,total,.keep_all=T),
mapping = aes(x=1.1))+
scale_fill_brewer(palette="Set1")+
theme_bw()+
theme(legend.position="top")+
labs(y="Self-reported ethnicity",fill="Genetic ancestry",x="Proportion")
png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/anc_vs_ethnicity.png",res=900,units="in",width=10,height=4)
p
dev.off()


# repeat with bigsnpr
library(bigsnpr)
library(tidyverse)

# download reference files
DIR = "/data/scratch/hmy117"
all_freq <- bigreadr::fread2(
  runonce::download_file("https://figshare.com/ndownloader/files/31620968",
                         dir = DIR, fname = "ref_freqs.csv.gz"))
projection <- bigreadr::fread2(
  runonce::download_file("https://figshare.com/ndownloader/files/31620953",
                         dir = DIR, fname = "projection.csv.gz"))

# match adams to reference

path_to_geno = "/data/scratch/hmy117/hgdp_1kg_genomes/adams_hg19_for_bigsnpr_cpra"
adams_snps = bigreadr::fread2(paste0(path_to_geno,".bim"),
  select = c(1, 4:6),
                   col.names = c("chr", "pos", "a1", "a0")) %>%
  mutate(beta = 1) %>%
  snp_match(all_freq[1:5]) %>%
  print()

# read matched SNPs
rds <- snp_readBed2(paste0(path_to_geno,".bed"),
 ind.col = adams_snps$`_NUM_ID_.ss`)
obj.bigsnp <- snp_attach(rds)
G <- obj.bigsnp$genotypes
G <- snp_fastImputeSimple(G)

# PCA projection
# project individuals (divided by 2) onto the PC space
PROJ <- as.matrix(projection[adams_snps$`_NUM_ID_`, -(1:5)])

correction <- c(1, 1, 1, 1.008, 1.021, 1.034, 1.052, 1.074, 1.099,
                1.123, 1.15, 1.195, 1.256, 1.321, 1.382, 1.443)
all_proj <- big_prodMat(G, sweep(PROJ, 2, correction / 2, '*'),
                        # scaling to get G if beta = 1 and (2 - G) if beta = -1
                        center = 1 - adams_snps$beta,
                        scale = adams_snps$beta)


X <- crossprod(PROJ,
               as.matrix(all_freq[adams_snps$`_NUM_ID_`, -(1:5)]))
               cp_X_pd <- Matrix::nearPD(crossprod(X), base.matrix = TRUE)
Amat <- cbind(1, diag(ncol(X)))
bvec <- c(1, rep(0, ncol(X)))

# define groups
group <- colnames(all_freq)[-(1:5)]
group[group %in% c("Scandinavia", "United Kingdom", "Ireland")]   <- "Europe (North West)"
group[group %in% c("Europe (South East)", "Europe (North East)")] <- "Europe (East)"
grp_fct <- factor(group, unique(group))


# assign to one group
all_centers <- t(X)
all_sq_dist <- apply(all_centers, 1, function(one_center) {
  rowSums(sweep(all_proj, 2, one_center, '-')^2)
})

THR <- 0.05  # you can adjust this threshold
thr_sq_dist <- max(dist(all_centers)^2) * THR / 0.16

cluster <- group[
  apply(all_sq_dist, 1, function(x) {
    ind <- which.min(x)
    if (isTRUE(x[ind] < thr_sq_dist)) ind else NA
  })
]

# read ancestry calls
ancestry_calls_hgdp_1kg = read_tsv("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls.tsv")
ancestry_calls_hgdp_1kg$bigsnpr_ancestry = cluster
write_tsv(ancestry_calls_hgdp_1kg,"/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls_detailed.tsv")

# plot
ncol = ancestry_calls_hgdp_1kg$bigsnpr_ancestry %>% unique %>% length
pal = colorRampPalette(RColorBrewer::brewer.pal(ncol, "Set1"))(ncol)
p=ggplot(ancestry_calls_hgdp_1kg,aes(predicted_ancestry,fill=bigsnpr_ancestry))+
geom_bar(position="fill",color="black")+
theme_minimal()+
scale_fill_manual(values = pal)+
labs(y="Proportion of samples",x="Inferred genetic ancestry \nfrom HGDP-1KG reference \nusing random forest classifier",fill="Inferred genetic ancestry\nwith UKB reference\nand bigsnpr method")

png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_vs_bigsnpr.png",res=900,units="in",width=7,height=6)
p
dev.off()

# counts
ancestry_calls_hgdp_1kg %>%
  group_by(predicted_ancestry) %>%
  dplyr::count(bigsnpr_ancestry) %>%
  mutate(pct = 100*n/sum(n)) %>%
  print(n=100)
````

## QC of imputed data

### Explore imputation quality
- Check imputation quality
- Examine snps in R
- Plot info in MAF bins

#### Combine stats from all chroms using bcftools
````unix
cd /data/scratch/hmy117/adams_imputed/
module load bcftools
rm info_stats_all_snps
touch info_stats_all_snps
for i in {1..22};
do
	echo doing chrom $i
	bcftools query -f '%CHROM %POS %INFO/MAF %REF %ALT %INFO/R2 %INFO/ER2\n' chr$i\.info.gz >> info_stats_all_snps
done
````

#### Inpsect in R & get SNPs with high INFO & MAF
````R
library(tidyverse)
setwd("/data/scratch/hmy117/adams_imputed/")
snps = read_table("info_stats_all_snps",col_names = F)
colnames(snps) = c("CHR","BP","MAF","REF", "ALT","INFO","ER2")

# cut into MAF bins
snps$maf_bin = Hmisc::cut2(snps$MAF,cuts = c(0,0.01,0.05,0.1,0.5))

# write genotyped snps for step1 regenie
snps_qcd_regenie = snps %>%
	filter(INFO >= 0.99 & MAF >= 0.05)


# find high-quality SNPs for downstream analyses
snps_qcd = snps %>%
	filter(INFO >= 0.7 & MAF >= 0.01)

# make new snp name
snps_qcd = snps_qcd %>%
	mutate(snp_name = paste0(CHR,":",BP,":",REF,":",ALT)) %>%
	dplyr::select(snp_name)
write_tsv(snps_qcd,"snps_to_keep_maf1e-2_info_0.7.tsv",col_names=F)

message("Before filtering N:")
print(nrow(snps))
message("After filtering N:")
print(nrow(snps_qcd))

snps_qcd_regenie = snps_qcd_regenie %>%
	mutate(snp_name = paste0(CHR,":",BP,":",REF,":",ALT)) %>%
	dplyr::select(snp_name)
write_tsv(snps_qcd_regenie,"snps_to_keep_step1_regenie.tsv",col_names=F)


# summarise per maf bin
summary_info = snps %>%
	group_by(maf_bin) %>%
	summarise(mean_info = mean(INFO), sd = sd(INFO))

png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/imputation_quality_maf.png",res = 300, units="in",width=4, height=4)
ggplot(summary_info,aes(maf_bin,mean_info))+
	geom_point(size=3)+
	geom_errorbar(mapping = aes(x=maf_bin,ymin = mean_info - sd,ymax = mean_info + sd),width=0.3)+
	theme_minimal()+
	labs(x="Minor allele frequency",y="Imputation quality (INFO score)")+
	scale_x_discrete(labels = c("<0.01","<0.05","<0.1","<0.5"))+
	scale_fill_brewer(palette="Set1")+
	theme(legend.position = "none")
dev.off()

# genotyped snps
genotyped = snps %>% filter(ER2 !=".")

png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/imputation_quality_r.png",res = 300, units="in",width=4, height=4)
ggplot(genotyped,aes(maf_bin,as.numeric(ER2),fill=maf_bin))+
geom_boxplot()+
theme_minimal()+
labs(x="Minor allele frequency",y="Imputation-Genotyping correlation (R)")+
scale_x_discrete(labels = c("<0.01","<0.05","<0.1","<0.5"))+
scale_fill_brewer(palette="Set1")+
theme(legend.position = "none")
dev.off()

p = ggplot(snps_qcd,aes(INFO,fill=maf_bin))+
geom_histogram(alpha=0.5,color="black")+
theme_minimal()+
scale_fill_brewer(palette="Set1")+
labs(x="Imputation quality score (INFO)",y="N SNPs",fill="MAF bin")
png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/imputation_quality_final_snps.png",res = 300, units="in",width=6, height=4)
p
dev.off()

````

### SNP QC
- SNP QC on individual VCFs
- Filter to INFO > 0.7 & MAF > 0.01 & missingness <10% and HWE P>1e-5
- Conversion back to plink
````unix
qsub ~/ADAMS/genotypes/QMUL_Aug_23/scripts/plink_snp_qc_imputed.sh
````
### Cambridge data QC
#### Run on CAM HPC
````unix
cd /rds/project/sjs1016/rds-sjs1016-msgen/Genotypes/Montreal/Imputed/
module load plink/2.00-alpha

# snp qc
for i in {1..22};
  do
    plink2 --pfile MS_GT_only_chr$i \
    --maf 0.05 \
    --hwe 1e-5 \
    --geno 0.1 \
    --make-bed \
    --out ~/rds/hpc-work/filtered_chr$i\_plink1 &
  done

# merge chroms
rm merge_filelist
for i in {2..22};
  do
    echo ~/rds/hpc-work/filtered_chr$i\_plink1.bed ~/rds/hpc-work/filtered_chr$i\_plink1.bim ~/rds/hpc-work/filtered_chr$i\_plink1.fam >> merge_filelist
  done

module unload plink
module load plink-1.9-gcc-5.4.0-sm3ojoi

plink --bfile ~/rds/hpc-work/filtered_chr1_plink1 \
--merge-list merge_filelist \
--make-bed \
--out merged_plink1_filtered

# filter merged file
plink --bfile merged_plink1_filtered \
--mind 0.1 \
--make-bed \
--out ./ancestry/outputs/merged_qcd_all_chroms

# tarball
cd /rds/project/sjs1016/rds-sjs1016-msgen/Genotypes/Montreal/Imputed/ancestry/outputs/
mkdir ancestry_inference
mv merged_qcd_all_chroms* ./ancestry_inference
tar czvf merged_chroms_for_ancestry_inference.tar.gz ancestry_inference
````

#### Uploaded to QM HPC
````unix
mkdir /data/scratch/hmy117/cambridge_genos
cd /data/scratch/hmy117/cambridge_genos

# unzip
tar -xvf "/data/home/hmy117/ADAMS/genotypes/Cambridge/merged_chroms_for_ancestry_inference.tar.gz"

# liftover to hg38
awk '{print "chr"$1,$4-1,$4,$2}' ./ancestry_inference/merged_qcd_all_chroms.bim > hg19_bedfile

# run liftover
/data/Wolfson-UKBB-Dobson/liftover/liftOver \
hg19_bedfile \
/data/Wolfson-UKBB-Dobson/liftover/hg38ToHg19.over.chain.gz \
hg38_bedfile \
unmapped

awk '{print $4,$3}' hg38_bedfile > hg38_snp_positions

# Update SNP positions
~/plink --bfile ./ancestry_inference/merged_qcd_all_chroms \
--update-map hg38_snp_positions \
--make-bed \
--out merged_qcd_all_chroms_temp_hg38

# reset var names to cpra
~/plink2 --bfile merged_qcd_all_chroms_temp_hg38 \
--set-all-var-ids @:#:\$r:\$a \
--make-bed \
--out merged_qcd_all_chroms_hg38_cpra

# find overlapping SNPs with hgdp
Rscript /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/find_compatible_snps.R \
merged_qcd_all_chroms_hg38_cpra.bim \
/data/scratch/hmy117/hgdp_1kg_genomes/combined_hgdp_1kg_nonmissing.bim

# filter 1kg
~/plink --bfile /data/scratch/hmy117/hgdp_1kg_genomes/combined_hgdp_1kg_nonmissing \
--extract snps_to_keep_file2.tsv \
--out filtered_snps_hgdp_1kg \
--make-bed

~/plink2 --bfile filtered_snps_hgdp_1kg \
--set-all-var-ids @:#:\$r:\$a \
--make-bed \
--out filtered_snps_hgdp_1kg_cpra

# filter cam
~/plink --bfile merged_qcd_all_chroms_hg38_cpra \
--out filtered_merged_qcd_all_chroms_hg38_cpra \
--extract snps_to_keep_file1.tsv \
--make-bed

# calculate PCs
~/plink2 --bfile filtered_snps_hgdp_1kg_cpra \
--pca allele-wts 50 \
--freq \
--out hgdp_kg_pcs

# rename ADAMS as cpra
~/plink2 --bfile ADAMS_qc_genos_for_pcs \
--set-all-var-ids @:#:\$r\:\$a \
--make-bed \
--out adams_geno_for_pcs_hg38_cpra

# project CAM samples
~/plink2 --bfile filtered_merged_qcd_all_chroms_hg38_cpra \
--read-freq hgdp_kg_pcs.afreq \
--score hgdp_kg_pcs.eigenvec.allele 2 5 header-read no-mean-imputation variance-normalize list-variants \
--score-col-nums 6-55 \
--out cam_pcs

# project original dataset
~/plink2 --bfile filtered_snps_hgdp_1kg_cpra \
--read-freq hgdp_kg_pcs.afreq \
--extract cam_pcs.sscore.vars \
--score hgdp_kg_pcs.eigenvec.allele 2 5 header-read no-mean-imputation variance-normalize \
--score-col-nums 6-55 \
--out hgdp_kg_pcs_rescored
````

#### Ancestry inference (CAM)
````R
library(tidyverse)
setwd("/data/scratch/hmy117/cambridge_genos")

# read in data
cam = read_table("cam_pcs.sscore")
kg_hgdp = read_table("hgdp_kg_pcs_rescored.sscore")
meta = read_tsv("../hgdp_1kg_genomes/gnomad_meta_v1.tsv") %>%
  dplyr::select(2,hgdp_tgp_meta.Population,hgdp_tgp_meta.Genetic.region)
colnames(meta) = c("IID","pop","superpop")
kg_hgdp = kg_hgdp %>%
left_join(meta,by="IID")

# build RF on HGDP data
# filter out those with missing labels
kg_hgdp = kg_hgdp %>%
  filter(!is.na(superpop)) %>%
  dplyr::select(superpop,contains("PC"))
library(caret)

rf_fit = train(superpop ~ .,
                      data=kg_hgdp,
                      method='rf',
                      metric='Accuracy')


# save rf
saveRDS(rf_fit,"rf_fit.rds")

# can reload here
# rf_fit = readRDS("rf_fit.rds")

# predict
cam$predicted_ancestry = predict(rf_fit,cam)

# count
counts = adams %>% dplyr::count(predicted_ancestry) %>% mutate(pct = n/sum(n))
counts = counts %>% arrange(desc(n))
counts$predicted_ancestry= factor(counts$predicted_ancestry,levels = counts$predicted_ancestry,ordered=T)
p=ggplot(counts,aes(n,predicted_ancestry,fill=predicted_ancestry,
	label=paste0(round(pct*100,2),"%")))+
	geom_col(color="black")+
	scale_fill_brewer(palette="Set1")+
	theme_minimal()+
	geom_text(hjust=0,position=position_nudge(x=10))+
	scale_x_continuous(limits = c(0,400))+
	labs(x="N",y="Inferred genetic ancestry")+
	theme(legend.position="none")
png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_counts.png",res=900,units="in",width=4,height=3)
p
dev.off()

adams %>%
	dplyr::count(predicted_ancestry) %>%
	mutate(total = sum(n), prop = n/total)

p=ggplot(adams,aes(PC1_AVG,PC2_AVG,col=predicted_ancestry))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC1",y="PC2",col="Inferred genetic ancestry")

p2=ggplot(adams,aes(PC1_AVG,PC2_AVG,col=predicted_ancestry))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC1",y="PC2",col="Genetic ancestry")+
  ggtitle("ADAMS")+
	scale_x_continuous(limits = c(-0.2,0.2))+
	scale_y_continuous(limits = c(-0.15,0.15))

p3 = ggplot(kg_hgdp %>% na.omit(),aes(PC1_AVG,PC2_AVG,col=superpop))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC1",y="PC2",col="Genetic ancestry")+
  ggtitle("1kg + HGDP reference")+
	scale_x_continuous(limits = c(-0.2,0.2))+
	scale_y_continuous(limits = c(-0.15,0.15))

p4=ggplot(adams,aes(PC3_AVG,PC4_AVG,col=predicted_ancestry))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC3",y="PC4",col="Genetic ancestry")+
  ggtitle("ADAMS")+
	scale_y_continuous(limits = c(-0.25,0.05))+
	scale_x_continuous(limits = c(-0.15,0.15))
p5 = ggplot(kg_hgdp %>% na.omit(),aes(PC3_AVG,PC4_AVG,col=superpop))+
  geom_point()+
  scale_color_brewer(palette="Set1")+
  theme_bw()+
  labs(x="PC3",y="PC4",col="Genetic ancestry")+
  ggtitle("1kg + HGDP reference")+
	scale_y_continuous(limits = c(-0.25,0.05))+
	scale_x_continuous(limits = c(-0.15,0.15))

png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/pc_plot_with_ref_pc1_4.png",res=900,units="in",width=10,height=8)
cowplot::plot_grid(p2,p4,p3,p5,align="v",ncol=2)
dev.off()

# write all ancestry calls
anc_calls = adams %>%
  dplyr::select(1,2,predicted_ancestry)
write_tsv(anc_calls,"/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls.tsv")



### Update fam files
- Modify IDs in R
````R
library(tidyverse)
setwd("/data/scratch/hmy117/adams_imputed/")

for(i in c(1:22)){
df = read_table(paste0("ADAMS_imputed_qc_chr",i,".fam"),col_names=F) %>%
	mutate(X1 = str_remove(X1,"^0_")) %>%
	tidyr::separate(X1,sep = "_",into = c("part1","oragene")) %>%
	dplyr::select(X2,oragene) %>%
	mutate(oldfid = X2, oldiid = X2, newfid = oragene, newiid = oragene) %>%
	dplyr::select(oldfid,oldiid,newfid,newiid)
write_tsv(df,paste0("chr",i,"_newids.tsv"),col_names = F)
}

````

#### Update IDs in PLINK
- Merge across chromosomes in PLINK
- Rename sample IDs
````unix
# rename IDs
cd /data/scratch/hmy117/adams_imputed/
for i in {22..1}; do ~/plink --bfile ADAMS_imputed_qc_chr$i --update-ids chr$i\_newids.tsv --out chr$i\_combined_adams_imputed_newids --make-bed; done
````

### Merge chromosomes
````unix
cd /data/scratch/hmy117/adams_imputed/
rm filelist_for_merge
for i in {2..22}; do echo chr$i\_combined_adams_imputed_newids >> filelist_for_merge; done
~/plink --bfile chr1_combined_adams_imputed_newids \
--merge-list filelist_for_merge \
--out combined_adams_imputed \
--make-bed
````

### Further QC
````R
library(tidyverse)
setwd("/data/scratch/hmy117/adams_imputed/")
snps = read_table("combined_adams_imputed.bim",col_names = F)

message(nrow(snps))

# exclude indels
snps = snps %>%
	filter(nchar(X5)==1 & nchar(X6)==1)

# exclude duplicate positions (i.e. non-biallelics)
dups = snps %>% dplyr::count(X1,X4)
dups =  dups %>% filter(n>1)

snps = snps %>% left_join(dups,by=c("X1","X4"))
snps = snps %>% filter(is.na(n)) %>% dplyr::select(-n)

message(nrow(snps))

write_tsv(snps,"non_duplicated_no_indel_snps.tsv",col_names=F)
````

### QC
````unix
cd /data/scratch/hmy117/adams_imputed/

~/plink --bfile combined_adams_imputed \
--extract non_duplicated_no_indel_snps.tsv \
--make-bed \
--maf 0.00999 \
--hwe 1e-5 \
--geno 0.1 \
--out combined_adams_imputed_qc \
--chr 1-22
````

### Individual QC
#### Missingness
````unix
cd /data/scratch/hmy117/adams_imputed/
~/plink --bfile combined_adams_imputed_qc \
--mind 0.1 \
--make-bed \
--out combined_adams_imputed_qc_mind_0.1
````
#### Heterozygosity
````unix
cd /data/scratch/hmy117/adams_imputed/
~/plink --bfile combined_adams_imputed_qc \
--indep-pairwise 1000 500 0.1 \
--out pruned_for_het_and_kinship

~/plink --bfile combined_adams_imputed_qc \
--extract pruned_for_het_and_kinship.prune.in \
--make-bed \
--out pruned_for_het_and_kinship_genotypes

~/plink --bfile pruned_for_het_and_kinship_genotypes \
--het small-sample \
--out het_check
````

````R
library(tidyverse)
setwd("/data/scratch/hmy117/adams_imputed/")
het = read_table("het_check.het")


p=ggplot(het,aes(F))+
	geom_histogram()+
	theme_minimal()+
	labs(x="Heterozygosity statistic (F)",y="N")+
	geom_vline(xintercept = mean(het$F)-5*sd(het$F),linetype="dashed",color="blue")+
	geom_vline(xintercept = mean(het$F)+5*sd(het$F),linetype="dashed",color="blue")
png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/het_stats.png",res=900,units="in",width=4,height=4)
p
dev.off()

````
### Kinship
#### Inference
````unix
cd /data/scratch/hmy117/adams_imputed/
~/king -b combined_adams_imputed_qc.bed --duplicate
~/king -b combined_adams_imputed_qc.bed --related --degree 3
~/plink --bfile combined_adams_imputed_qc --missing --out missingness_report
````

#### Plot missingness
````R
library(tidyverse)
setwd("/data/scratch/hmy117/adams_imputed/")
miss = read_table("missingness_report.imiss")

miss$F_MISS %>% summary()

p=ggplot(miss,aes(F_MISS))+
	geom_histogram()+
	theme_minimal()+
	labs(x="Proportion of missing genotypes\n(per individual)",y="N")
png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/missing_stats.png",res=900,units="in",width=4,height=4)
p
dev.off()

````

#### Validate duplicates
````R
library(tidyverse)
setwd("/data/scratch/hmy117/adams_imputed/")
kinship  = read_table("king.kin0",col_types=cols(.default="c"))
dups = kinship %>%
	filter(InfType == "Dup/MZ" )
data.frame(ID = c(dups$ID1,dups$ID2))  %>%
distinct(ID)

covars = read_tsv("~/ADAMS/genotypes/QMUL_Aug_23/pheno/adams_covars.tsv",col_types=cols(.default="c"))
matches = dups %>%
	dplyr::select(ID1,ID2,Kinship) %>%
	left_join(covars %>%
			mutate(ID1 = IID) %>% dplyr::select(-IID,-FID),
			by = "ID1") %>%
	left_join(covars %>%
			mutate(ID2 = IID) %>% dplyr::select(-IID,-FID),
			by = "ID2")
matches = matches %>%
	mutate(delta_age = abs(as.numeric(age_at_recruitment.x) - as.numeric(age_at_recruitment.y))) %>%
	arrange(desc(delta_age))

write_csv(matches,"~/ADAMS/genotypes/QMUL_Aug_23/outputs/duplicates.csv")

# write file for exclusion
# preferentially keep covariate data
people_to_exclude = matches %>%
  mutate(person_to_exclude = ifelse(is.na(age_at_recruitment.x) | is.na(Sex.x),ID1,ID2 )) %>%
  dplyr::select(person_to_exclude)


exclusion = people_to_exclude %>%
  mutate(FID = person_to_exclude, IID = person_to_exclude) %>%
  dplyr::select(FID,IID)
write_tsv(exclusion,"dups_to_exclude")
````
#### Exclusion
````unix
~/plink --bfile combined_adams_imputed_qc \
--remove dups_to_exclude \
--make-bed \
--out combined_adams_imputed_qc_unrelated

# copy to home folder
cp combined_adams_imputed_qc_unrelated* ~/ADAMS/genotypes/QMUL_Aug_23/outputs/
````

## Severity GWAS

### PCA
````unix
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/

# split ancestry groups
awk 'NR>1{if($3=="CSA") print $2,$2}' ./outputs/ancestry_calls.tsv > ./outputs/sas_iids
awk 'NR>1{if($3=="AFR") print $2,$2}' ./outputs/ancestry_calls.tsv > ./outputs/afr_iids
awk 'NR>1{if($3=="EUR") print $2,$2}' ./outputs/ancestry_calls.tsv > ./outputs/eur_iids

# recompute PCs within each cluster
for ancestry in sas eur afr
do
	~/plink2 \
	--bfile ./outputs/combined_adams_imputed_qc_unrelated \
	--keep ./outputs/$ancestry\_iids \
	--maf 0.05 \
	--geno 0.01 \
	--indep-pairwise 1000 100 0.1 \
	--out ./outputs/$ancestry\_pruned

	# filter
	~/plink2 \
	--bfile ./outputs/combined_adams_imputed_qc_unrelated \
	--keep ./outputs/$ancestry\_iids \
	--extract ./outputs/$ancestry\_pruned.prune.in \
	--pca 10 \
	--out ./outputs/$ancestry\_pcs
done
````

#### Make covar & pheno files
````R
library(tidyverse)
library(RNOmni)
setwd("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/")

ancestry_calls_hgdp_1kg = read_tsv("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls_detailed.tsv") %>% dplyr::select(IID,contains("ancestry"))
cov = read_tsv("./pheno/adams_covars.tsv") %>% dplyr::select(-FID)
all_cov = ancestry_calls_hgdp_1kg %>% left_join(cov,by="IID")
pheno = read_tsv("./pheno/adams_pheno.tsv") %>% dplyr::select(-FID)

# loop through each ancestry to find outliers & process phenotype data

# find outliers
find_outliers_process_pheno = function(ancestry,sd_num=2){

  # make elbow plot
  eigenvals = read_table(paste0("./outputs/",ancestry,"_pcs.eigenval"),col_names=F) %>%
    mutate(pve = X1 / sum(X1)) %>%
    mutate(cum_pve = cumsum(pve)) %>%
    mutate(PC = row_number())

  p= ggplot(eigenvals,aes(PC,cum_pve))+
    geom_line()+
    geom_point(shape=21,fill="white",color="black",size=3)+
    geom_hline(yintercept=0.9,linetype="dashed")+
    geom_vline(xintercept = which(eigenvals$cum_pve>0.9)[1],linetype="dashed")+
    theme_bw()+
    labs(x="Principal component",y="Cumulative proportion variance explained")+
    ggtitle(toupper(ancestry))+
    scale_x_continuous(breaks=c(1:10))
    png(paste0("./outputs/pca_elbow_",ancestry,".png"),res=900,units="in",width=6,height=4)
    print(p)
    dev.off()


	pcs = read_table(paste0("./outputs/",ancestry,"_pcs.eigenvec")) %>% dplyr::select(-1)

	mean_pc1 = mean(pcs$PC1)
	mean_pc2 = mean(pcs$PC2)
	sd_pc1 = sd(pcs$PC1)
	sd_pc2 = sd(pcs$PC2)
	upper_pc1 = mean_pc1 + sd_num*sd_pc1
	upper_pc2 = mean_pc2 + sd_num*sd_pc2
	lower_pc1 = mean_pc1 - sd_num*sd_pc1
	lower_pc2 = mean_pc2 - sd_num*sd_pc2

	pcs = pcs %>%
		mutate(outlier = ifelse(PC1 > upper_pc1 | PC1 < lower_pc1 | PC2 > upper_pc2 | PC2 < lower_pc2,
			"outlier",
			"keep"))
	message("PCA outliers:")
	print(pcs %>% dplyr::count(outlier))		
	# save outliers to file
	outliers = pcs %>% filter(outlier=="outlier") %>% dplyr::select(IID) %>% mutate(FID = IID)
	write_tsv(outliers,paste0("./outputs/pca_outliers_",ancestry,".tsv"))

	# combine with main covar file
	pcs = pcs  %>% left_join(all_cov,by="IID")
	p = ggplot(pcs %>% filter(outlier=="keep"),aes(PC1,PC2,fill = bigsnpr_ancestry))+
		geom_point(size=3,data = pcs %>% filter(outlier!="keep"),alpha=0.5,shape=21)+
		geom_point(size=3,color="black",shape=21)+
		theme_bw()+
		scale_fill_brewer(palette="Paired")+
		labs(fill="Ancestry group")+
		ggtitle(toupper(ancestry))

	png(paste0("./outputs/pca_outliers_",ancestry,".png"),res=900,units="in",width=6,height=4)
	print(p)
	dev.off()

	# write covar file
	pcs = pcs %>% filter(!is.na(PC1)) %>% dplyr::select(-contains("ancestry")) %>% mutate(FID = IID) %>% dplyr::select(FID,IID,contains("age"),contains("sex"),contains("PC")) %>% na.omit()
	write_tsv(pcs,paste0("./pheno/",ancestry,"_covars_with_pcs.tsv"))

	# make pheno file
	pheno = pheno %>%
		filter(IID %in% pcs$IID)

	# join with pcs
	pheno = pheno %>%
		dplyr::select(IID,gARMSS,edss) %>%
		na.omit() %>%
		mutate(FID = IID) %>%
		dplyr::select(FID,IID,gARMSS,edss)

	write_tsv(pheno,paste0("./pheno/",ancestry,"_pheno.tsv"))

}

find_outliers_process_pheno(ancestry="sas")
find_outliers_process_pheno(ancestry="afr")
find_outliers_process_pheno(ancestry="eur")

````

#### Run GWAS
````unix
# regenie GWAS
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/

# remove PCA outliers and filter to MAF 0.05 within each cluster
for ancestry in sas eur afr;
do
	# filter in PLINK
	~/plink2 --bfile ./outputs/combined_adams_imputed_qc_unrelated \
	--keep ./outputs/$ancestry\_iids \
	--remove ./outputs/pca_outliers_$ancestry\.tsv \
	--make-bed \
	--out ./outputs/filtered_genotypes_for_sev_gwas_$ancestry\_hg38 \
  --mac 20
done
qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/regenie_gwas_severity.sh
````

#### Power calc
````R

library(tidyverse)

# set maf
maf = 0.4

sample_size = 100

beta = 0.5
n_iter=100
p_thresh = 5e-8

find_power = function(beta=0.5,maf=0.4,sample_size=100){
pvals = list()
for(i in c(1:n_iter)){

  # simulate genotypes
  genotypes = data.frame(geno = rbinom(prob = maf, size = 2, n= sample_size))

  # simulate normally-distributed outcome with mean = 0 and sd=1 in homs
  homs = genotypes %>% filter(geno == 0)
  homs$pheno = rnorm(mean = 0, sd = 1, n = nrow(homs))
  hets = genotypes %>% filter(geno == 1)
  hets$pheno = rnorm(mean = 0 + beta, sd = 1, n = nrow(hets))
  rare_homs = genotypes %>% filter(geno == 2)
  rare_homs$pheno = rnorm(mean = 0 + 2*beta, sd = 1, n = nrow(rare_homs))

  # combine
  dat = bind_rows(homs,hets,rare_homs)

  # normalise outcome
  dat$pheno = RNOmni::RankNorm(dat$pheno)

  # model
  pval = summary(lm(data = dat, pheno ~ geno))$coefficients[2,4]
  pvals[[i]] = pval
  }
  power = sum(unlist(pvals)<p_thresh) / n_iter

  power
}


betas = seq(0.1,3,by=0.1)
mafs = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5)
sample_size = c(300)
params = expand.grid(b = betas, maf = mafs, n = sample_size)

powers = list()
for(i in c(1:nrow(params))){
  message(i," of ",nrow(params))
  powers[[i]] = find_power(params$b[i], params$maf[i], params$n[i])
}

params$power = unlist(powers)

ggplot(params,aes(b,power,fill=factor(maf)))+
geom_line()+
geom_point(size=3,shape=21,color="black")+
labs(x="Beta",fill="MAF",y="Power")+
theme_bw()+
geom_hline(yintercept=0.8, linetype="dashed")

````

#########
# PICK UP HERE 10-01
#########


#### VEP
````unix
# prepare snps for vep
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/

# print hits at P < 1e-3
rm ./outputs/vep_input
for ancestry in sas eur afr
do
	awk 'NR>1{if($12>3) print $1,$2,$2,$4"/"$5,"+",$3}' ./outputs/sev_gwas_$ancestry\_gARMSS_INT.regenie >> ./outputs/vep_input
done

# annotate all hits with P <1e-3
module load ensembl-vep

~/ensembl-vep/vep -i ./outputs/vep_input -o ./outputs/snp_annotations_nearest \
--cache \
--dir_cache /data/scratch/hmy117/.vep \
--force_overwrite \
--nearest symbol \
--tab --fields "Uploaded_variation,Location,Allele,Gene,NEAREST,Consequence,Existing_variation"


````

#### Combine with IMSGC severity GWAS
##### Liftover to hg19 (for UKB)
````unix

# lift over to hg38
cd /data/home/hmy117/ADAMS/genotypes/IMSGC_GWAS
awk 'NR>1{print "chr"$1,$3-1,$3,$2}' imsgc_mssev_discovery.tsv > hg19_bedfile

# run liftover
/data/Wolfson-UKBB-Dobson/liftover/liftOver \
hg19_bedfile \
/data/Wolfson-UKBB-Dobson/liftover/hg19ToHg38.over.chain.gz \
hg38_bedfile \
unmapped
````
##### Liftover to hg19 (for UKB)
````R
library(tidyverse)
setwd("/data/home/hmy117/ADAMS/genotypes/IMSGC_GWAS")
imsgc_sev = read_tsv("imsgc_mssev_discovery.tsv")
hg38_positions = read_table("hg38_bedfile",col_names=F)

# prepare for merge
hg38_positions = hg38_positions %>%
			dplyr::select(X3,X4) %>%
			dplyr::rename("SNP" = X4,"BP_hg38" = X3)

# find duplicate positions
dups = hg38_positions %>%
	dplyr::count(SNP) %>%
	filter(n>1)

# filter to biallelics
hg38_positions = hg38_positions %>%
	filter(!SNP %in% dups$SNP)

# filter
imsgc_sev = imsgc_sev %>%
	filter(SNP %in% hg38_positions$SNP)


# merge
imsgc_sev = imsgc_sev %>%
	left_join(hg38_positions,by="SNP")

# write to file
write_tsv(imsgc_sev %>% dplyr::select(-POS) %>% dplyr::rename("POS" = BP_hg38),"imsgc_mssev_discovery_hg38.tsv")
````

#### Explore GWAS results
````R
library(tidyverse)
setwd("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/")
# read in GWAS
read_regenie_gwas = function(x){
  read_table(x, col_types = cols_only(
		  CHROM = col_double(),
		  GENPOS = col_double(),
		  ID = col_character(),
		  ALLELE0 = col_character(),
		  ALLELE1 = col_character(),
		  A1FREQ = col_double(),
		  N = col_double(),
		  TEST = col_character(),
		  BETA = col_double(),
		  SE = col_double(),
		  CHISQ = col_double(),
		  LOG10P = col_double())) %>%
  filter(TEST == "ADD" & !is.na(LOG10P)) %>%
  dplyr::rename("CHR" = CHROM, "BP" = GENPOS, "SNP" = ID) %>%
  dplyr::select(-TEST) %>%
	mutate(P = 10^-LOG10P)
}

# define ancestries
ancestries=c("afr","sas","eur")

# read in gwas
all_res = purrr::map(ancestries,function(x){
	gwas_res = read_regenie_gwas(
		paste0("./outputs/sev_gwas_",x,"_gARMSS.regenie")) %>%
	mutate(anc = x)
	gwas_res
})

# combine
all_res = do.call("bind_rows",all_res)

# read in edss gwas
all_res_edss = purrr::map(ancestries,function(x){
	gwas_res = read_regenie_gwas(
		paste0("./outputs/sev_gwas_",x,"_edss.regenie")) %>%
	mutate(anc = x)
	gwas_res
})

# combine
all_res_edss = do.call("bind_rows",all_res_edss)

# compare armss gwas vs edss
all_res_edss_and_armss = all_res %>% left_join(all_res_edss, by = c("CHR","BP","SNP","ALLELE0","ALLELE1","anc"))
sampled_dat = all_res_edss_and_armss %>% filter(P.x < 0.05 | P.y < 0.05)
ggplot(sampled_dat,aes(BETA.x,BETA.y))+
geom_point()+
geom_abline(intercept=0,slope=1,linetype="dashed",color="red")

# split by ancestry
eur_adams = all_res %>% filter(anc == "eur")
afr_adams = all_res %>% filter(anc == "afr")
sas_adams = all_res %>% filter(anc == "sas")

# add annotations
anno = read_table("./outputs/snp_annotations_nearest",skip=31,col_types = cols(.default="c")) %>%
	dplyr::select(1,NEAREST)
colnames(anno) = c("SNP","Gene")
anno = anno %>% distinct()

# inflation
qqplots = list()
make_qq_plot = function(ancestry){
	gwas_res = all_res %>% filter(anc == ancestry)
	lambda = median(qchisq(gwas_res$P,df=1,lower.tail=F)) /  qchisq(0.5,lower.tail=F,df=1)
	message(ancestry)
	message(lambda)
	pval_dat = data.frame(observed = -log10(gwas_res$P)) %>%
		arrange(observed)
	pval_dat = pval_dat %>%
		mutate(expected = -log10(seq(1,1/nrow(pval_dat),by=-1/nrow(pval_dat))))

	#	downsample but ensure top snps are included
	pval_dat$index = seq(1,nrow(pval_dat),by=1)
	tophits = tail(pval_dat,round(nrow(pval_dat)*0.01,0))
	sampled_pval_dat = sample_frac(pval_dat,0.05) %>% bind_rows(tophits) %>% distinct()

	# plot
	p = ggplot(sampled_pval_dat,aes(expected,observed))+
		geom_abline(intercept=0,slope=1,color="red",linetype="dashed")+
		geom_point()+
		labs(x="Expected -log10(P)",y="Observed -log10(P)")+
		ggtitle(paste0("Ancestry: ",toupper(ancestry),"\nLambda =  ",round(lambda,2)))+
		theme_bw()

	qqplots[[length(qqplots)+1]] <<- p
	png(paste0("./outputs/qq_plot_",ancestry,".png"),res=900,units="in",width=4,height=4)
	print(p)
	dev.off()

}
sapply(ancestries,make_qq_plot)

# print all together
library(gridExtra)
png("./outputs/all_qq_plots.png",res=900,units="in",width=4,height=8)
cowplot::plot_grid(plotlist = qqplots,align="v",ncol=1)
dev.off()


# manhattans
manhattans =list()
make_manhattans = function(ancestry){
	gwas_res = all_res %>% filter(anc == ancestry)

	# get coords
	coords = gwas_res %>%
		group_by(CHR) %>%
		summarise(min_bp = min(BP),max_bp=max(BP),median_bp = median(BP))

	new_coords = coords %>%
		mutate(CHR = CHR+1) %>%
		mutate(cumbp = cumsum(max_bp))

	midpoints = coords$median_bp+c(0,new_coords$cumbp[1:21])
	gwas_res = gwas_res %>%
			left_join(new_coords,by="CHR") %>%
			mutate(cum_bp = ifelse(is.na(cumbp),BP,BP+cumbp))

	# colors
	gwas_res = gwas_res %>%
		mutate(significance = case_when(
			P < 1e-5 ~ "sig",
			CHR %% 2 == 0 ~ "even",
			CHR %% 2 != 0 ~ "odd"
			))

	col_pal = c("lavenderblush1","lavenderblush2","orange")
	names(col_pal) = c("even","odd","sig")

	plot_dat = gwas_res %>% filter(P < 0.05)
	p=ggplot(plot_dat,aes(cum_bp,-log10(P),col=significance))+
		geom_hline(yintercept = 5,color="blue",linetype="dashed",alpha=0.5)+
		geom_point()+
		scale_color_manual(values = col_pal)+
		scale_x_continuous(breaks = midpoints,labels = c(1:22))+
		ggrepel::geom_label_repel(plot_dat %>%
			filter(P < 1e-5 & SNP %in% anno$SNP) %>%
			left_join(anno,by="SNP") %>%
			group_by(CHR) %>%
			slice_min(P,with_ties=F) %>%
			distinct(Gene,.keep_all=T),
		mapping = aes(label = Gene),min.segment.length = 0,color="black",nudge_y=1,direction = "x")+
		labs(x="Genomic position (hg38)",y="-log10(P)")+
		ggtitle(paste0("GWAS of gARMSS in ",toupper(ancestry)))+
		theme_bw()+
		theme(legend.position="none")

	manhattans[[length(manhattans)+1]] <<- p

	png(paste0("./outputs/manhattan_plot_garmss",ancestry,".png"),res=900,units="in",width=10,height=4)
	print(p)
	dev.off()		
}

sapply(ancestries,make_manhattans)

# print all together
png("./outputs/all_manhattans_plots.png",res=900,units="in",width=10,height=10)
cowplot::plot_grid(plotlist = manhattans,align="v",ncol=1)
dev.off()

# compare with IMSGC GWAS
imsgc_hg38 = read_tsv("/data/home/hmy117/ADAMS/genotypes/IMSGC_GWAS/imsgc_mssev_discovery_hg38.tsv")

# join on chr:pos
all_res_with_imsgc = imsgc_hg38 %>%
		dplyr::rename("BP"=POS,"ALLELE1" = A1,"ALLELE0" = A2,"A1FREQ" = AF1) %>%
		mutate(chrpos = paste0(CHR,":",BP)) %>%
		mutate(anc = "IMSGC") %>%
		bind_rows(all_res %>% mutate(chrpos = paste0(CHR,":",BP)))

# get sig snps in IMSGC
all_res_with_imsgc %>% filter(anc=="IMSGC" & P < 5e-7) %>% dplyr::select(chrpos,SNP,P)

# forest
make_forest = function(snp){
  plot_dat = all_res_with_imsgc %>% filter(chrpos == snp)

  # Add study label
  plot_dat = plot_dat %>%
  	mutate(anc = ifelse(anc == "IMSGC","IMSGC-EUR",paste0("ADAMS-",toupper(anc))))

  # flip beta if necessary
  plot_dat = plot_dat %>%
  	mutate(BETA = ifelse(ALLELE1 == plot_dat$ALLELE1[1],BETA,BETA*-1))

  print(plot_dat)

  # refactor
  plot_dat$anc = factor(plot_dat$anc,levels = c("IMSGC-EUR","ADAMS-EUR","ADAMS-SAS","ADAMS-AFR"),ordered=T)
  pictured_allele = paste0(snp,"-",plot_dat$ALLELE1[1])
  ggplot(plot_dat,aes(BETA,anc,fill=anc))+
  	geom_errorbarh(mapping = aes(xmin = BETA - 1.96*SE,xmax = BETA + 1.96*SE,y=anc),height=0.3)+
  	geom_point(shape=21,color="black",size=3)+
  	geom_vline(xintercept=0,linetype="dashed")+
  	theme_bw()+
  	labs(x=paste0("Effect of ",pictured_allele," on gARMSS"),y="Study & ancestry")+
  	theme(legend.position="none")
}

# PICK UP HERE 05-1
snp = "2:71449869"
png("./outputs/dysf_snp.png",res=900,units="in",width=6,height=6)
make_forest("2:71449869")
dev.off()

png("./outputs/dnm3_snp.png",res=900,units="in",width=6,height=6)
make_forest("1:200258565")
dev.off()

# region plot

make_locus_plot = function(chr,pos,window=1e6){
  plot_dat = all_res_with_imsgc %>% filter(CHR == chr & BP > pos - window/2 & BP < pos + window/2)

  # Add study label
  plot_dat = plot_dat %>%
  	mutate(anc = ifelse(anc == "IMSGC","IMSGC-EUR",paste0("ADAMS-",toupper(anc))))

  # refactor
  plot_dat$anc = factor(plot_dat$anc,levels = c("IMSGC-EUR","ADAMS-EUR","ADAMS-SAS","ADAMS-AFR"),ordered=T)

  plot_dat %>%
    group_by(anc) %>%
    slice_min(P) %>%
    dplyr::select(SNP,A1FREQ,BETA,SE,P,anc) %>%
    print()
  ggplot(plot_dat,aes(BP,-log10(P),fill=anc))+
  	geom_point(shape=21,color="black",size=3)+
  	geom_hline(yintercept=-log10(1e-5),linetype="dashed")+
  	theme_bw()+
    facet_wrap(~anc,ncol=1)+
  	theme(legend.position="none")
}

png("./outputs/dysf_locus_plot.png",res=900,units="in",width=6,height=8)
make_locus_plot(chr=2,pos=71449869,window=5e5)
dev.off()


# global beta beta plots
sig_imsgc_hits = all_res_with_imsgc %>% filter(anc=="IMSGC" & P < 1e-5) %>% dplyr::select(chrpos,SNP,P)
all_res_sig_imsgc_hits = all_res_with_imsgc %>% filter(SNP %in% sig_imsgc_hits$SNP)
````

## Susceptibility GWAS


### Liftover to hg19 (for UKB)
````unix

# lift over to hg19
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/

awk '{print "chr"$1,$4-1,$4,$2}' combined_adams_imputed_qc_unrelated.bim > hg38_bedfile

# run liftover
/data/Wolfson-UKBB-Dobson/liftover/liftOver \
hg38_bedfile \
/data/Wolfson-UKBB-Dobson/liftover/hg38ToHg19.over.chain.gz \
hg19_bedfile \
unmapped

awk '{print $4,$3}' hg19_bedfile > hg19_snp_positions

# Update SNP positions
~/plink --bfile combined_adams_imputed_qc_unrelated \
--update-map hg19_snp_positions \
--make-bed \
--out combined_adams_imputed_qc_temp_hg19

# reset var names to cpra
~/plink2 --bfile combined_adams_imputed_qc_temp_hg19 \
--set-all-var-ids @:#:\$r:\$a \
--make-bed \
--out combined_adams_imputed_qc_hg19_cpra
````

### Merge with UKB
#### Find compatible SNPs
````R
library(tidyverse)

# read ukb snps
ukb_snps = list()
for(i in c(1:22)){
	ukb_snps[[i]] = read_table(paste0("/data/Wolfson-PNU-dementia/UKB/imputed_genotypes/plink2_files/chr_",i,".pvar"))
}
ukb_snps = do.call("bind_rows",ukb_snps)

# read adams snps
adams_snps  = read_table("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/combined_adams_imputed_qc_hg19_cpra.bim",col_names = F)
colnames(adams_snps) = c("#CHROM","ID","X3","POS","REF","ALT")

# find intersection of chr:pos
adams_snps = adams_snps %>% mutate(chrpos = paste0(`#CHROM`,":",POS))
ukb_snps = ukb_snps %>% mutate(chrpos = paste0(`#CHROM`,":",POS))

combo_snps = inner_join(adams_snps,ukb_snps,by="chrpos")

# clean up columns
combo_snps = combo_snps %>% dplyr::select(-`#CHROM.y`,-X3,-POS.y)

# check compatible alleles
combo_snps = combo_snps %>%
	mutate(compatible = ifelse(
		(REF.x == REF.y & ALT.x == ALT.y) |
		(REF.x == ALT.y & ALT.x == REF.y),
		"compatible","incompatible")) %>%
		filter(compatible == "compatible")

# write snp list to keep
ukb_snps_to_keep = combo_snps %>% dplyr::select(ID.y)
ukb_snps_names_to_update = combo_snps %>% dplyr::select(ID.y,ID.x)

write_tsv(ukb_snps_to_keep,"/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ukb_snps_to_keep.tsv",col_names = F)
write_tsv(ukb_snps_names_to_update,"/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ukb_snps_to_update_names.tsv",col_names = F)

````

#### Filter to compatible SNPs

````unix
qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/filter_ukb_files.sh
````

#### Merge UKB files and ADAMS genotypes across chromosomes
````unix
qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/merge_ukb_files.sh
````


# test
# merge this chromosome
SGE_TASK_ID=5
~/plink --bfile  /data/scratch/hmy117/adams_genotypes_chr${SGE_TASK_ID}  \
--freq

--chr ${SGE_TASK_ID} \
--bmerge /data/scratch/hmy117/adams_genotypes_chr${SGE_TASK_ID}  \
--make-bed \
--out /data/scratch/hmy117/ukb_adams_merged_genotypes_chr${SGE_TASK_ID}



#### Merge all UKB-ADAMS chroms together
````unix

# clean up
for i in {1..22}; do rm /data/scratch/hmy117/ukb_chr$i\_cpra.* ; done
for i in {1..22}; do rm /data/scratch/hmy117/filtered_ukb_chr$i\_hg19_cpra.* ; done
for i in {1..22}; do rm /data/scratch/hmy117/filtered_ukb_chr$i\_hg19_cpra_nodups.* ; done
for i in {1..22}; do rm /data/scratch/hmy117/ukb_chr$i\_filtered_tmp.* ; done
for i in {1..22}; do rm /data/scratch/hmy117/filtered_ukb_chr$i\.* ; done

qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/merge_all_chroms_adams_ukb.sh
````

#### QC on combined dataset
````unix

# exclude palindromes

awk '{if( ($5=="A" && $6=="T") || ($5=="T" && $6=="A") || ($5=="G" && $6=="C") || ($5=="C" && $6=="G")) print $2}' /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms.bim > /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_palindromic_snps_to_exclude

~/plink --bfile /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms \
--maf 0.05 \
--exclude /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_palindromic_snps_to_exclude \
--hwe 1e-5 \
--geno 0.1 \
--allow-no-sex \
--out /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_no_palindromes \
--make-bed \
--make-pheno /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/combined_adams_imputed_qc_hg19_cpra.fam \*

# differential missingness (between UKB & ADAMS)
## Excluded SNPs with >10% missingness in either cohort or with diff missingness P < 1e-5
~/plink --bfile /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_no_palindromes \
--test-missing \
--allow-no-sex \
--out ukb_adams_all_chroms_diff_missing
awk 'NR>1{if($3<0.1 && $4<0.1 && $5 > 1e-5) print $2}' ukb_adams_all_chroms_diff_missing.missing > /data/scratch/hmy117/non_diff_missing_snps_ukb_adams_all_chroms

# filter to these snps
~/plink2 --bfile /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_no_palindromes \
--extract /data/scratch/hmy117/non_diff_missing_snps_ukb_adams_all_chroms \
--out /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_no_palindromes_qc \
--make-bed

# clean up
# rm /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms.*
# rm /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_no_palindromes.*

````

#### Joint PCA on combined dataset
````unix

cd /data/scratch/hmy117/hgdp_1kg_genomes/

# liftover
awk '{print "chr"$1,$4-1,$4,$2}' combined_hgdp_1kg_unrelated.bim > hg38_bedfile

# run liftover
/data/Wolfson-UKBB-Dobson/liftover/liftOver \
hg38_bedfile \
/data/Wolfson-UKBB-Dobson/liftover/hg38ToHg19.over.chain.gz \
hg19_bedfile \
unmapped

awk '{print $4,$3}' hg19_bedfile > hg19_snp_positions

# Update SNP positions
~/plink --bfile combined_hgdp_1kg_unrelated \
--update-map hg19_snp_positions \
--make-bed \
--out combined_hgdp_1kg_unrelated_hg19

# reset var names to cpra
~/plink2 --bfile combined_hgdp_1kg_unrelated_hg19 \
--set-all-var-ids @:#:\$r:\$a \
--make-bed \
--out combined_hgdp_1kg_unrelated_hg19_cpra

# filter to UKB-ADAMS vars
~/plink2 --bfile combined_hgdp_1kg_unrelated_hg19_cpra \
--extract /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_no_palindromes_qc.bim \
--out combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry \
--make-bed

# prune
~/plink2 --bfile combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry \
--indep-pairwise 1000 500 0.05 \
--out combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry_prune

~/plink2 --bfile combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry \
--out combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry_pruned \
--extract combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry_prune.prune.in \
--make-bed


# calculate PCs
~/plink2 --bfile combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry_pruned \
--pca allele-wts 50 \
--freq \
--out hgdp_kg_pcs_with_ukb

# project ADAMS samples
~/plink2 --bfile /data/scratch/hmy117/ukb_adams_merged_genotypes_all_chroms_no_palindromes_qc \
--read-freq hgdp_kg_pcs_with_ukb.afreq \
--score hgdp_kg_pcs_with_ukb.eigenvec.allele 2 5 header-read no-mean-imputation variance-normalize list-variants \
--score-col-nums 6-55 \
--out ukb_adams_pcs

# project original dataset
~/plink2 --bfile combined_hgdp_1kg_unrelated_hg19_cpra_for_ancestry_pruned \
--read-freq hgdp_kg_pcs_with_ukb.afreq \
--extract ukb_adams_pcs.sscore.vars \
--score hgdp_kg_pcs_with_ukb.eigenvec.allele 2 5 header-read no-mean-imputation variance-normalize \
--score-col-nums 6-55 \
--out hgdp_kg_pcs_with_ukb_rescored
````

#### Identify ancestry groupings
````R
library(tidyverse)
setwd("/data/scratch/hmy117/hgdp_1kg_genomes")

# read in data
adams_ukb = read_table("ukb_adams_pcs.sscore")
kg_hgdp = read_table("hgdp_kg_pcs_with_ukb_rescored.sscore")
meta = read_tsv("gnomad_meta_v1.tsv") %>%
  dplyr::select(2,hgdp_tgp_meta.Population,hgdp_tgp_meta.Genetic.region)
colnames(meta) = c("IID","pop","superpop")
kg_hgdp = kg_hgdp %>%
left_join(meta,by="IID")


# build RF on HGDP data
# filter out those with missing labels
kg_hgdp = kg_hgdp %>%
  filter(!is.na(superpop)) %>%
  dplyr::select(superpop,contains("PC"))
library(caret)

rf_fit = train(superpop ~ .,
                      data=kg_hgdp,
                      method='rf',
                      metric='Accuracy')


# save rf
saveRDS(rf_fit,"rf_fit_with_ukb.rds")

# can reload here
# rf_fit = readRDS("rf_fit_with_ukb.rds")

# predict
adams_ukb$predicted_ancestry = predict(rf_fit,adams_ukb)

# validate these ancestry calls
# read in original adams ancestry calls
ancestry_calls_hgdp_1kg = read_tsv("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls_detailed.tsv") %>% dplyr::select(IID,contains("ancestry"))
cov = read_tsv("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/pheno/adams_covars.tsv") %>% dplyr::select(-FID)
all_cov = ancestry_calls_hgdp_1kg %>% left_join(cov,by="IID")

# merge
adams_ukb = adams_ukb %>%
	mutate(study = ifelse(IID %in% all_cov$IID,"ADAMS","UKB")) %>%
	left_join(all_cov,by="IID")

# counts
adams_ukb %>% dplyr::count(predicted_ancestry.x,study)
adams_ukb %>% filter(study=="ADAMS") %>%
	group_by(predicted_ancestry.x) %>%
	dplyr::count(predicted_ancestry.y) %>%
	mutate(prop = n/sum(n))
adams_ukb %>% filter(study=="ADAMS") %>%
		dplyr::count(predicted_ancestry.x == predicted_ancestry.y) %>%
		mutate(prop = n/sum(n))

# read ukb pheno
# get phenotype data for UKB
ukb_pheno = read_csv("/data/Wolfson-PNU-dementia/UKB/PRS_April_2023/phenodata/PRS_59138r672130.csv") %>%
	dplyr::select(EID,sex_f31_0_0,age_at_recruitment_f21022_0_0,genetic_ethnic_grouping_f22006_0_0,contains("g35"))

# bring in ethnicity data
pheno = readRDS("/data/Wolfson-PNU-dementia/UKB/datasets/sheenastrux/78867r672482/78867r672482_FO.rds") %>%
	tibble %>%
	dplyr::select(eid,contains("ethnic"))
id_bridge = read_csv("/data/Wolfson-PNU-dementia/UKB/datasets/sheenastrux/59138_78867/Bridge_eids_59138_78867.csv")
pheno = pheno %>%
  dplyr::rename("eid_78867" = eid) %>%
  left_join(id_bridge,by="eid_78867") %>%
  dplyr::rename("EID" = eid_59138)
pheno = pheno %>% dplyr::select(EID,contains("ethnic"))
ukb_pheno = ukb_pheno %>% left_join(pheno,by="EID")

# join with UKB pheno
adams_ukb = adams_ukb %>%
	dplyr::rename("EID" = IID) %>%
	left_join(ukb_pheno,by="EID")

# plot overall PC space
p1 = ggplot(adams_ukb,aes(PC1_AVG,PC2_AVG,fill=predicted_ancestry.x))+
  geom_point(shape=21,color="black",size=3)+
  scale_fill_brewer(palette="Set1")+
  theme_bw()+
	facet_wrap(~study) +
  labs(x="PC1",y="PC2",fill="Genetic ancestry")

p2 = ggplot(adams_ukb,aes(PC3_AVG,PC4_AVG,fill=predicted_ancestry.x))+
  geom_point(shape=21,color="black",size=3)+
  scale_fill_brewer(palette="Set1")+
  theme_bw()+
	facet_wrap(~study) +
  labs(x="PC3",y="PC4",fill="Genetic ancestry")

p3 = ggplot(adams_ukb,aes(PC5_AVG,PC6_AVG,fill=predicted_ancestry.x))+
  geom_point(shape=21,color="black",size=3)+
  scale_fill_brewer(palette="Set1")+
  theme_bw()+
	facet_wrap(~study) +
  labs(x="PC5",y="PC6",fill="Genetic ancestry")

png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ukb_adams_pc_plot_with_ref_pc1_6.png",res=900,units="in",width=8,height=12)
cowplot::plot_grid(p1,p2,p3,align="v",ncol=1)
dev.off()

# validate with self-reported ethnicity
adams_ukb_with_ethnicity = adams_ukb %>%
	filter(!is.na(adams_ukb$ethnic_background_f21000_0_0))%>%
	filter(predicted_ancestry.x %in% c("AFR","EUR","CSA"))
ethnicities_to_plot = adams_ukb_with_ethnicity %>%
	dplyr::count(ethnic_background_f21000_0_0) %>%
	filter(n>200)

p = ggplot(adams_ukb_with_ethnicity %>% filter(ethnic_background_f21000_0_0 %in% ethnicities_to_plot$ethnic_background_f21000_0_0),
aes(ethnic_background_f21000_0_0,fill=predicted_ancestry.x))+
  geom_bar(position="fill",color="black")+
  theme_bw()+
	coord_flip()+
	scale_fill_brewer(palette="Set1")+
	labs(y="Proportion of individuals",x="Self-reported ethnicity",fill="Inferred genetic ancestry")

png("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ukb_adams_pcs_vs_self_report.png",res=900,units="in",width=8,height=6)
p
dev.off()

# write all ancestry calls
anc_calls = adams_ukb %>%
  dplyr::select(1,2,predicted_ancestry.x) %>%
	dplyr::rename("IID" = EID)
anc_calls %>% dplyr::count(predicted_ancestry.x)
write_tsv(anc_calls,"/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls_all_ukb_adams.tsv")
````

#### Identify ancestry groupings (part 2)

##### Split into ancestry groups
````unix
qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/split_ancestry_groups.sh
````

##### Joint PCA on combined dataset within each ancestry
````unix
qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/run_pca_ukb_adams.sh
````


#########################################
# PICK UP HERE 09-01
# RUNNING WITH 20 PCs, think about other ways of countering inflation
# THINK ABOUT
# - BETTER PCA INFERENCE
# - other causes inflation in case-control
# - downstream analysis for severity
# check this has worked for EUR
#########################################
##### Filter out PCA outliers within each ancestry
````R
library(tidyverse)
setwd("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/")


# read ukb pheno
# get phenotype data for UKB
ukb_pheno = read_csv("/data/Wolfson-PNU-dementia/UKB/PRS_April_2023/phenodata/PRS_59138r672130.csv") %>%
	dplyr::select(EID,sex_f31_0_0,age_at_recruitment_f21022_0_0,genetic_ethnic_grouping_f22006_0_0,contains("g35"))

# bring in ethnicity data
pheno = readRDS("/data/Wolfson-PNU-dementia/UKB/datasets/sheenastrux/78867r672482/78867r672482_FO.rds")
pheno = pheno %>% tibble %>% dplyr::select(eid,contains("ethnic"))
id_bridge = read_csv("/data/Wolfson-PNU-dementia/UKB/datasets/sheenastrux/59138_78867/Bridge_eids_59138_78867.csv")
pheno = pheno %>%
  dplyr::rename("eid_78867" = eid) %>%
  left_join(id_bridge,by="eid_78867") %>%
  dplyr::rename("EID" = eid_59138)
pheno = pheno %>% dplyr::select(EID,contains("ethnic"))
ukb_pheno = ukb_pheno %>% left_join(pheno,by="EID")

# read in adams initial ancestry calls
ancestry_calls_hgdp_1kg = read_tsv("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/outputs/ancestry_calls_detailed.tsv") %>% dplyr::select(IID,contains("ancestry"))
cov = read_tsv("./pheno/adams_covars.tsv") %>% dplyr::select(-FID)
all_cov = ancestry_calls_hgdp_1kg %>% left_join(cov,by="IID")

# find outliers
find_outliers_process_pheno = function(ancestry,sd_num=2,out_ancestry){

	# read in pcs
	infile = paste0("/data/scratch/hmy117/adams_ukb_pca_projections_",out_ancestry,".eigenvec")
	pcs = read_tsv(infile)

  # define study
  pcs = pcs %>%
    mutate(study = ifelse(IID %in% all_cov$IID,"ADAMS","UKB"))

	# get pc limits
	mean_pc1 = mean(pcs$PC1)
	mean_pc2 = mean(pcs$PC2)
	sd_pc1 = sd(pcs$PC1)
	sd_pc2 = sd(pcs$PC2)
	upper_pc1 = mean_pc1 + sd_num*sd_pc1
	upper_pc2 = mean_pc2 + sd_num*sd_pc2
	lower_pc1 = mean_pc1 - sd_num*sd_pc1
	lower_pc2 = mean_pc2 - sd_num*sd_pc2

  # define outliers
	pcs = pcs %>%
		mutate(outlier = ifelse(
			PC1 > upper_pc1 | PC1 < lower_pc1 | PC2 > upper_pc2 | PC2 < lower_pc2,
			"outlier",
			"keep"))
	message("PCA outliers:")
	print(pcs %>% dplyr::count(study,outlier))		

	# save keepers to file
	non_outliers = pcs %>% filter(outlier!="outlier") %>% dplyr::select(IID) %>% mutate(FID = IID)
	write_tsv(non_outliers,paste0("./outputs/ukb_pca_non_outliers_",out_ancestry,".tsv"))

	# plot pcs with and without outliers
	p = ggplot(pcs,aes(PC1,PC2,fill = outlier))+
		geom_point(size=3,color="black",shape=21)+
		theme_bw()+
    facet_wrap(~study)+
		scale_fill_brewer(palette="Set1")+
		labs(fill="Ancestry group")+
		ggtitle(toupper(ancestry))
	png(paste0("./outputs/ukb_adams_pca_outliers_",ancestry,".png"),res=900,units="in",width=8,height=4)
	print(p)
	dev.off()


	# combine with main covar file
	pcs = pcs %>%
		filter(outlier=="keep") %>%
		dplyr::select(-outlier)

	# merge
	pcs = pcs %>%
		left_join(all_cov %>% dplyr::select(IID,age_at_recruitment,Sex),by="IID")

	# filter to this ancestry
	ukb_pheno_this_ancestry = ukb_pheno %>%
		filter(EID %in% pcs$IID) %>%
		dplyr::rename("IID" = EID,"Sex" = sex_f31_0_0,"age_at_recruitment" = age_at_recruitment_f21022_0_0)


	# split covar / pheno into UKB and non-UKB
	ukb_pheno_this_ancestry_tmp = pcs %>%
		filter(study =="UKB") %>%
		dplyr::select(-Sex,-age_at_recruitment) %>%
		left_join(ukb_pheno_this_ancestry,by="IID")

	ukb_pheno_this_ancestry_tmp = ukb_pheno_this_ancestry_tmp	%>%
		mutate(MS_status = ifelse(!is.na(ukb_pheno_this_ancestry_tmp$source_of_report_of_g35_multiple_sclerosis_f131043_0_0),2,1))

	adams_pheno_tmp = pcs %>%
		filter(study == "ADAMS") %>%
		mutate(MS_status = 2)

  # check UKB labels vs ethnicity
  abundant_groups =  ukb_pheno_this_ancestry_tmp %>%
      dplyr::count(ethnic_background_f21000_0_0) %>%
      filter(n>50)

  p = ggplot(ukb_pheno_this_ancestry_tmp %>%
    filter(ethnic_background_f21000_0_0 %in% abundant_groups$ethnic_background_f21000_0_0),aes(PC1,PC2,col=ethnic_background_f21000_0_0))+
  geom_point()

  png(paste0("./outputs/ukb_adams_pca_outliers_controls_by_ethnicity_",ancestry,".png"),res=900,units="in",width=8,height=4)
	print(p)
	dev.off()

	# recombine
	all_pheno_cov = bind_rows(adams_pheno_tmp,ukb_pheno_this_ancestry_tmp)

	# write covar file
	all_cov = all_pheno_cov %>%
		filter(!is.na(PC1)) %>%
		dplyr::select(-contains("genetic"),-contains("g35")) %>%
		mutate(FID = IID) %>%
		dplyr::select(FID,IID,contains("age"),contains("sex"),contains("PC")) %>%
		na.omit()


	write_tsv(all_cov,paste0("./pheno/susceptibility_",out_ancestry,"_covars_with_pcs.tsv"))

	# make pheno file
	all_pheno = all_pheno_cov %>%
		mutate(FID = IID) %>%
		dplyr::select(FID,IID,MS_status) %>%
		na.omit()

	write_tsv(all_pheno,paste0("./pheno/susceptibility_",out_ancestry,"_pheno.tsv"))

	all_pheno_cov %>% dplyr::count(MS_status,study) %>% print()
}

find_outliers_process_pheno(ancestry="CSA",out_ancestry="sas")
find_outliers_process_pheno(ancestry="AFR",out_ancestry="afr")
find_outliers_process_pheno(ancestry="EUR",out_ancestry="eur")


````

#### GWAS
#### Run GWAS
````unix

qsub /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/scripts/regenie_gwas_susceptibility.sh

````

#### VEP
````unix
# prepare snps for vep
cd /data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/

module load R/4.2.2


# liftover
for ancestry in sas eur afr
do
	Rscript ./scripts/liftover_hg19_to_hg38.R ./outputs/susceptibility_gwas_$ancestry\_MS_status.regenie
	awk 'NR>1{if($15>7.3) print $1,$18,$18,$3"/"$4,"+",$2}' ./outputs/susceptibility_gwas_$ancestry\_MS_status.regenie_hg38 > ./outputs/susceptibility_vep_input_$ancestry

# annotate
module load ensembl-vep
~/ensembl-vep/vep -i ./outputs/susceptibility_vep_input_$ancestry -o ./outputs/snp_annotations_nearest_susceptibility_$ancestry \
--cache \
--dir_cache /data/scratch/hmy117/.vep \
--force_overwrite \
--nearest symbol \
--tab --fields "Uploaded_variation,Location,Allele,Gene,NEAREST,Consequence,Existing_variation"
done

````


#### Combine with IMSGC risk GWAS
##### Liftover to hg38
````unix

# lift over to hg38
cd /data/home/hmy117/ADAMS/genotypes/IMSGC_GWAS
awk 'NR>1{print "chr"$1,$2-1,$2,$3}' discovery_metav3.0.meta > hg19_bedfile

# run liftover
/data/Wolfson-UKBB-Dobson/liftover/liftOver \
hg19_bedfile \
/data/Wolfson-UKBB-Dobson/liftover/hg19ToHg38.over.chain.gz \
hg38_bedfile \
unmapped
````

##### Liftover to hg38
````R
library(tidyverse)
setwd("/data/home/hmy117/ADAMS/genotypes/IMSGC_GWAS")
imsgc_risk = read_table("discovery_metav3.0.meta")
hg38_positions = read_table("hg38_bedfile",col_names=F)

# prepare for merge
hg38_positions = hg38_positions %>%
			dplyr::select(X3,X4) %>%
			dplyr::rename("SNP" = X4,"BP_hg38" = X3)

# find duplicate positions
dups = hg38_positions %>%
	dplyr::count(SNP) %>%
	filter(n>1)

# filter to biallelics
hg38_positions = hg38_positions %>%
	filter(!SNP %in% dups$SNP)

# filter
imsgc_risk = imsgc_risk %>%
	filter(SNP %in% hg38_positions$SNP)

# merge
imsgc_risk = imsgc_risk %>%
	left_join(hg38_positions,by="SNP")

# add beta
imsgc_risk = imsgc_risk %>%
  mutate(BETA = log(OR))

# add se
imsgc_risk = imsgc_risk %>%
  mutate(
    Z = qnorm(1 - (P / 2)  ) ,
    SE = BETA / Z
    )

# replace hg19 positions
imsgc_risk = imsgc_risk %>%
  dplyr::select(-BP,-SNP) %>%
  dplyr::rename("BP" = BP_hg38) %>%
  mutate(SNP = paste0(CHR,":",BP))

# write to file
write_tsv(imsgc_risk,"imsgc_ms_risk_discovery_hg38.tsv")
````

##### Get allele freqs in UKB vs ADAMS EUR cases


#### Explore GWAS results
````R
library(tidyverse)
setwd("/data/home/hmy117/ADAMS/genotypes/QMUL_Aug_23/")
# read in GWAS
read_regenie_gwas = function(x){
  read_table(x, col_types = cols_only(
		  CHROM = col_double(),
		  GENPOS = col_double(),
		  ID = col_character(),
		  ALLELE0 = col_character(),
		  ALLELE1 = col_character(),
		  A1FREQ = col_double(),
      A1FREQ_CASES = col_double(),
      A1FREQ_CONTROLS = col_double(),      
		  N = col_double(),
      N_CONTROLS = col_double(),
      N_CASES = col_double(),
		  TEST = col_character(),
		  BETA = col_double(),
		  SE = col_double(),
		  CHISQ = col_double(),
		  LOG10P = col_double())) %>%
  filter(TEST == "ADD" & !is.na(LOG10P)) %>%
  dplyr::rename("CHR" = CHROM, "BP" = GENPOS, "SNP" = ID) %>%
  dplyr::select(-TEST) %>%
	mutate(P = 10^-LOG10P)
}

# define ancestries
ancestries=c("afr","sas","eur")

# read in gwas
all_res = purrr::map(ancestries,function(x){
	gwas_res = read_regenie_gwas(
		paste0("./outputs/susceptibility_gwas_",x,"_MS_status.regenie_hg38")) %>%
	mutate(anc = x)
	gwas_res
})

# combine
all_res = do.call("bind_rows",all_res)

# manhattans
make_manhattans = function(ancestry){
	gwas_res = all_res %>% filter(anc == ancestry)

	# read annotations

	anno = read_table(paste0("./outputs/snp_annotations_nearest_susceptibility_",ancestry),skip=31,col_types = cols(.default="c"))
  anno = anno %>%
		dplyr::select(1,NEAREST)
	colnames(anno) = c("SNP","Gene")
	anno = anno %>% distinct()

  # get coords
	coords = gwas_res %>%
		group_by(CHR) %>%
		summarise(min_bp = min(BP),max_bp=max(BP),median_bp = median(BP))

	new_coords = coords %>%
		mutate(CHR = CHR+1) %>%
		mutate(cumbp = cumsum(max_bp))

	midpoints = coords$median_bp+c(0,new_coords$cumbp[1:21])
	gwas_res = gwas_res %>%
			left_join(new_coords,by="CHR") %>%
			mutate(cum_bp = ifelse(is.na(cumbp),BP,BP+cumbp))

	# colors
	gwas_res = gwas_res %>%
		mutate(significance = case_when(
			P < 5e-8 ~ "sig",
			CHR %% 2 == 0 ~ "even",
			CHR %% 2 != 0 ~ "odd"
			))

	col_pal = c("lavenderblush1","lavenderblush2","orange")
	names(col_pal) = c("even","odd","sig")

	plot_dat = gwas_res %>% filter(P < 0.05)
	p=ggplot(plot_dat,aes(cum_bp,-log10(P),col=significance))+
		geom_hline(yintercept = -log10(5e-8),color="blue",linetype="dashed",alpha=0.5)+
		geom_point()+
		scale_color_manual(values = col_pal)+
		scale_x_continuous(breaks = midpoints,labels = c(1:22))+
		ggrepel::geom_label_repel(plot_dat %>%
			filter(P < 5e-8 & SNP %in% anno$SNP) %>%
			left_join(anno,by="SNP") %>%
			group_by(CHR) %>%
			slice_min(P,with_ties=F) %>%
			distinct(Gene,.keep_all=T),
		mapping = aes(label = Gene),min.segment.length = 0,color="black",nudge_y=1,direction = "x")+
		labs(x="Genomic position (hg38)",y="-log10(P)")+
		ggtitle(paste0("GWAS of MS risk in ",toupper(ancestry)))+
		theme_bw()+
		theme(legend.position="none")


	png(paste0("./outputs/manhattan_plot_susceptibility",ancestry,".png"),res=900,units="in",width=10,height=4)
	print(p)
	dev.off()		 

  # check allele counts
  gwas_res = gwas_res %>%
  mutate(AC_case = A1FREQ_CASES * (2 * N_CASES ) ) %>%
  mutate(AC_cont = A1FREQ_CONTROLS * (2 * N_CONTROLS ) )

  # filter to MAC 20 in cases and controls
  gwas_res = gwas_res %>% filter(AC_case >= 20 & AC_cont >= 20)

  # write annotations
  gwas_res %>%
    left_join(anno,by="SNP") %>%
    filter(P<5e-8) %>%
    dplyr::select(SNP,ALLELE0,ALLELE1,A1FREQ,BETA,P,Gene) %>%
    group_by(Gene) %>%
    slice_min(P) %>%
    arrange(P)

}

sapply(ancestries,make_manhattans)


# inflation
qqplots = list()
make_qq_plot = function(ancestry){
	gwas_res = all_res %>% filter(anc == ancestry)
	lambda = median(qchisq(gwas_res$P,df=1,lower.tail=F)) /  qchisq(0.5,lower.tail=F,df=1)
	message(ancestry)
	message(lambda)
	pval_dat = data.frame(observed = -log10(gwas_res$P)) %>%
		arrange(observed)
	pval_dat = pval_dat %>%
		mutate(expected = -log10(seq(1,1/nrow(pval_dat),by=-1/nrow(pval_dat))))

	#	downsample but ensure top snps are included
	pval_dat$index = seq(1,nrow(pval_dat),by=1)
	tophits = tail(pval_dat,round(nrow(pval_dat)*0.01,0))
	sampled_pval_dat = sample_frac(pval_dat,0.05) %>% bind_rows(tophits) %>% distinct()

	# plot
	p = ggplot(sampled_pval_dat,aes(expected,observed))+
		geom_abline(intercept=0,slope=1,color="red",linetype="dashed")+
		geom_point()+
		labs(x="Expected -log10(P)",y="Observed -log10(P)")+
		ggtitle(paste0("Ancestry: ",toupper(ancestry),"\nLambda =  ",round(lambda,2)))+
		theme_bw()

	qqplots[[length(qqplots)+1]] <<- p
	png(paste0("./outputs/qq_plot_susceptibility_",ancestry,".png"),res=900,units="in",width=4,height=4)
	print(p)
	dev.off()

}
sapply(ancestries,make_qq_plot)

# print all together
library(gridExtra)
png("./outputs/all_qq_plots.png",res=900,units="in",width=4,height=8)
cowplot::plot_grid(plotlist = qqplots,align="v",ncol=1)
dev.off()




# print all together
png("./outputs/all_manhattans_plots.png",res=900,units="in",width=10,height=10)
cowplot::plot_grid(plotlist = manhattans,align="v",ncol=1)
dev.off()

# compare with IMSGC GWAS
# read IMSGC risk GWAS (hg38 )
imsgc_risk_hg38 = read_tsv("/data/home/hmy117/ADAMS/genotypes/IMSGC_GWAS/imsgc_ms_risk_discovery_hg38.tsv",col_types="dccdddddddc")

# join on chr:pos
all_res_with_imsgc = imsgc_risk_hg38 %>%
		dplyr::rename("ALLELE1" = A1,"ALLELE0" = A2) %>%
		mutate(chrpos = paste0(CHR,":",BP)) %>%
		mutate(anc = "IMSGC") %>%
		bind_rows(all_res %>% mutate(chrpos = paste0(CHR,":",BP)))

# get sig snps in IMSGC
all_res_with_imsgc %>% filter(anc=="IMSGC" & P < 5e-7) %>% dplyr::select(chrpos,SNP,P)


# forest
make_forest = function(snp){
  plot_dat = all_res_with_imsgc %>% filter(chrpos == snp)

  # Add study label
  plot_dat = plot_dat %>%
  	mutate(anc = ifelse(anc == "IMSGC","IMSGC-EUR",paste0("ADAMS-",toupper(anc))))

  # flip beta if necessary
  plot_dat = plot_dat %>%
  	mutate(BETA = ifelse(ALLELE1 == plot_dat$ALLELE1[1],BETA,BETA*-1))

  # refactor
  plot_dat$anc = factor(plot_dat$anc,levels = c("IMSGC-EUR","ADAMS-EUR","ADAMS-SAS","ADAMS-AFR"),ordered=T)
  pictured_allele = paste0(snp,"-",plot_dat$ALLELE1[1])
  ggplot(plot_dat,aes(BETA,anc,fill=anc))+
  	geom_errorbarh(mapping = aes(xmin = BETA - 1.96*SE,xmax = BETA + 1.96*SE,y=anc),height=0.3)+
  	geom_point(shape=21,color="black",size=3)+
  	geom_vline(xintercept=0,linetype="dashed")+
  	theme_bw()+
  	labs(x=paste0("Effect of ",pictured_allele," on gARMSS"),y="Study & ancestry")+
  	theme(legend.position="none")
}

# PICK UP HERE 05-1
snp = "2:71449869"
png("./outputs/dysf_snp.png",res=900,units="in")
make_forest("2:71449869")
dev.off()

png("./outputs/edem_snp.png",res=900,units="in",width=6,height=6)
make_forest("3:5290006")
dev.off()

# region plot

make_locus_plot = function(chr,pos){
  plot_dat = all_res_with_imsgc %>% filter(CHR == chr & BP > pos - 5e5 & BP < pos + 5e5)

  # Add study label
  plot_dat = plot_dat %>%
  	mutate(anc = ifelse(anc == "IMSGC","IMSGC-EUR",paste0("ADAMS-",toupper(anc))))

  # refactor
  plot_dat$anc = factor(plot_dat$anc,levels = c("IMSGC-EUR","ADAMS-EUR","ADAMS-SAS","ADAMS-AFR"),ordered=T)

  ggplot(plot_dat,aes(BP,-log10(P),fill=anc))+
  	geom_point(shape=21,color="black",size=3)+
  	geom_hline(yintercept=-log10(1e-5),linetype="dashed")+
  	theme_bw()+
    facet_wrap(~anc,ncol=1)+
  	theme(legend.position="none")
}

make_locus_plot(chr=5,pos=113772162)
make_locus_plot(chr=1,pos=200258565)
make_locus_plot(chr=13,pos=81469972)

make_locus_plot(chr=3,pos=5290006)

````
